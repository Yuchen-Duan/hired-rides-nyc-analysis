{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 285;\n",
       "                var nbb_unformatted_code = \"# import libraries\\n\\nfrom math import radians, sin, cos, sqrt, atan2\\n\\n# import os\\nimport requests\\nimport bs4\\nimport re\\nimport geopandas\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport sqlalchemy as db\";\n",
       "                var nbb_formatted_code = \"# import libraries\\n\\nfrom math import radians, sin, cos, sqrt, atan2\\n\\n# import os\\nimport requests\\nimport bs4\\nimport re\\nimport geopandas\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport sqlalchemy as db\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# import os\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 286;\n",
       "                var nbb_unformatted_code = \"# notebook formatting\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# notebook formatting\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# notebook formatting\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# any constants you might need, for example:\\n\\nTAXI_URL = \\\"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\\\"\\n# add other constants to refer to any local data, e.g. uber & weather\\nUBER_CSV = \\\"uber_rides_sample.csv\\\"\\n\\nNEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\\n\\nDATABASE_URL = \\\"sqlite:///project.db\\\"\\nDATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\nQUERY_DIRECTORY = \\\"queries\\\"\";\n",
       "                var nbb_formatted_code = \"# any constants you might need, for example:\\n\\nTAXI_URL = \\\"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\\\"\\n# add other constants to refer to any local data, e.g. uber & weather\\nUBER_CSV = \\\"uber_rides_sample.csv\\\"\\n\\nNEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\\n\\nDATABASE_URL = \\\"sqlite:///project.db\\\"\\nDATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\nQUERY_DIRECTORY = \\\"queries\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26fe17",
   "metadata": {},
   "source": [
    "    \"\"\"Summary line.\n",
    "\n",
    "    Extended description of function.\n",
    "\n",
    "    Args:\n",
    "        arg1 (int): Description of arg1\n",
    "        arg2 (str): Description of arg2\n",
    "\n",
    "    Returns:\n",
    "        bool: Description of return value\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 291;\n",
       "                var nbb_unformatted_code = \"def calculate_distance(from_coord, to_coord):\\n    \\\"\\\"\\\"Caculate the distance between two coordinates\\n\\n    Args:\\n        from_coord (tuple): A pair values (float) of latitude and longitude\\n        to_coord (tuple): A pair values (float) of latitude and longitude\\n\\n    Returns:\\n        float: the distance, round to 3 decimals\\n\\n    \\\"\\\"\\\"\\n\\n    # convert degrees to radians\\n    lat1, lon1 = radians(from_coord[0]), radians(from_coord[1])\\n    lat2, lon2 = radians(to_coord[0]), radians(to_coord[1])\\n\\n    # apply Haversine formula\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n\\n    r = 6373.0  # radius of earth (km)\\n\\n    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\\n\\n    distance = round(r * c, 3)\\n\\n    return distance\";\n",
       "                var nbb_formatted_code = \"def calculate_distance(from_coord, to_coord):\\n    \\\"\\\"\\\"Caculate the distance between two coordinates\\n\\n    Args:\\n        from_coord (tuple): A pair values (float) of latitude and longitude\\n        to_coord (tuple): A pair values (float) of latitude and longitude\\n\\n    Returns:\\n        float: the distance, round to 3 decimals\\n\\n    \\\"\\\"\\\"\\n\\n    # convert degrees to radians\\n    lat1, lon1 = radians(from_coord[0]), radians(from_coord[1])\\n    lat2, lon2 = radians(to_coord[0]), radians(to_coord[1])\\n\\n    # apply Haversine formula\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n\\n    r = 6373.0  # radius of earth (km)\\n\\n    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\\n\\n    distance = round(r * c, 3)\\n\\n    return distance\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_distance(from_coord, to_coord):\n",
    "    \"\"\"Caculate the distance between two coordinates\n",
    "\n",
    "    Args:\n",
    "        from_coord (tuple): A pair values (float) of latitude and longitude\n",
    "        to_coord (tuple): A pair values (float) of latitude and longitude\n",
    "\n",
    "    Returns:\n",
    "        float: the distance, round to 3 decimals\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert degrees to radians\n",
    "    lat1, lon1 = radians(from_coord[0]), radians(from_coord[1])\n",
    "    lat2, lon2 = radians(to_coord[0]), radians(to_coord[1])\n",
    "\n",
    "    # apply Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    r = 6373.0  # radius of earth (km)\n",
    "\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = round(r * c, 3)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "bf6e6a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.8135468911925"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 288;\n",
       "                var nbb_unformatted_code = \"calculate_distance(NEW_YORK_BOX_COORDS[0], NEW_YORK_BOX_COORDS[1])\";\n",
       "                var nbb_formatted_code = \"calculate_distance(NEW_YORK_BOX_COORDS[0], NEW_YORK_BOX_COORDS[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_distance(NEW_YORK_BOX_COORDS[0], NEW_YORK_BOX_COORDS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def find_taxi_parquet_urls():\\n    \\\"\\\"\\\"Retrieve the yellow taxi parquet urls.\\n\\n    The function retrieves the url from January 2009 through June 2015.\\n\\n    Args:\\n        None\\n\\n    Returns:\\n        list: Desired urls as list of strings\\n\\n    \\\"\\\"\\\"\\n\\n    # Use requests library to get TAXI_URL html\\n    response = requests.get(TAXI_URL)\\n    html = response.content\\n\\n    # Use BeautifulSoup to get all yellow taxi parquet urls\\n    soup = bs4.BeautifulSoup(html, \\\"html.parser\\\")\\n    yellow_a_tags = soup.find_all(\\\"a\\\", attrs={\\\"title\\\": \\\"Yellow Taxi Trip Records\\\"})\\n    yellow_taxi_urls = [a[\\\"href\\\"] for a in yellow_a_tags]\\n\\n    # Use re moduel to filter the urls\\n    pattern = re.compile(\\n        r\\\"yellow_tripdata_20(09-(?:0\\\\d|1[0-2])|1[0-4]-(?:0\\\\d|1[0-2])|15-0[1-6]).parquet\\\"\\n    )\\n\\n    yellow_taxi_urls_desired = []\\n\\n    for link in yellow_taxi_urls:\\n        match = pattern.search(link)\\n        if match:\\n            yellow_taxi_urls_desired.append(match.string)\\n\\n    return yellow_taxi_urls_desired\";\n",
       "                var nbb_formatted_code = \"def find_taxi_parquet_urls():\\n    \\\"\\\"\\\"Retrieve the yellow taxi parquet urls.\\n\\n    The function retrieves the url from January 2009 through June 2015.\\n\\n    Args:\\n        None\\n\\n    Returns:\\n        list: Desired urls as list of strings\\n\\n    \\\"\\\"\\\"\\n\\n    # Use requests library to get TAXI_URL html\\n    response = requests.get(TAXI_URL)\\n    html = response.content\\n\\n    # Use BeautifulSoup to get all yellow taxi parquet urls\\n    soup = bs4.BeautifulSoup(html, \\\"html.parser\\\")\\n    yellow_a_tags = soup.find_all(\\\"a\\\", attrs={\\\"title\\\": \\\"Yellow Taxi Trip Records\\\"})\\n    yellow_taxi_urls = [a[\\\"href\\\"] for a in yellow_a_tags]\\n\\n    # Use re moduel to filter the urls\\n    pattern = re.compile(\\n        r\\\"yellow_tripdata_20(09-(?:0\\\\d|1[0-2])|1[0-4]-(?:0\\\\d|1[0-2])|15-0[1-6]).parquet\\\"\\n    )\\n\\n    yellow_taxi_urls_desired = []\\n\\n    for link in yellow_taxi_urls:\\n        match = pattern.search(link)\\n        if match:\\n            yellow_taxi_urls_desired.append(match.string)\\n\\n    return yellow_taxi_urls_desired\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_taxi_parquet_urls():\n",
    "    \"\"\"Retrieve the yellow taxi parquet urls.\n",
    "\n",
    "    The function retrieves the url from January 2009 through June 2015.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        list: Desired urls as list of strings\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Use requests library to get TAXI_URL html\n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "\n",
    "    # Use BeautifulSoup to get all yellow taxi parquet urls\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    yellow_taxi_urls = [a[\"href\"] for a in yellow_a_tags]\n",
    "\n",
    "    # Use re moduel to filter the urls\n",
    "    pattern = re.compile(\n",
    "        r\"yellow_tripdata_20(09-(?:0\\d|1[0-2])|1[0-4]-(?:0\\d|1[0-2])|15-0[1-6]).parquet\"\n",
    "    )\n",
    "\n",
    "    yellow_taxi_urls_desired = []\n",
    "\n",
    "    for link in yellow_taxi_urls:\n",
    "        match = pattern.search(link)\n",
    "        if match:\n",
    "            yellow_taxi_urls_desired.append(match.string)\n",
    "\n",
    "    return yellow_taxi_urls_desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b7a2fe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 348;\n",
       "                var nbb_unformatted_code = \"find_taxi_parquet_urls()\";\n",
       "                var nbb_formatted_code = \"find_taxi_parquet_urls()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find_taxi_parquet_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bb298bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def download_taxi_data(taxi_parquet_url):\\n    for url in taxi_parquet_url:\\n\\n        response = requests.get(url, stream=True)\\n        file_name = url.split(\\\"/\\\")[-1]\\n        # file_path = os.getcwd() + '/datasets/yellow_taxi_data/'\\n\\n        with open(file_name, \\\"wb\\\") as f:\\n            for chunk in response.iter_content(chunk_size=1024):\\n                if chunk:\\n                    f.write(chunk)\";\n",
       "                var nbb_formatted_code = \"def download_taxi_data(taxi_parquet_url):\\n    for url in taxi_parquet_url:\\n\\n        response = requests.get(url, stream=True)\\n        file_name = url.split(\\\"/\\\")[-1]\\n        # file_path = os.getcwd() + '/datasets/yellow_taxi_data/'\\n\\n        with open(file_name, \\\"wb\\\") as f:\\n            for chunk in response.iter_content(chunk_size=1024):\\n                if chunk:\\n                    f.write(chunk)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download_taxi_data(taxi_parquet_url):\n",
    "    for url in taxi_parquet_url:\n",
    "\n",
    "        response = requests.get(url, stream=True)\n",
    "        file_name = url.split(\"/\")[-1]\n",
    "        # file_path = os.getcwd() + '/datasets/yellow_taxi_data/'\n",
    "\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30a25ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Download the taxi parquet files to the current folder\\n\\ntaxi_parquet_url = find_taxi_parquet_urls()\\ndownload_taxi_data(taxi_parquet_url)\";\n",
       "                var nbb_formatted_code = \"# Download the taxi parquet files to the current folder\\n\\ntaxi_parquet_url = find_taxi_parquet_urls()\\ndownload_taxi_data(taxi_parquet_url)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the taxi parquet files to the current folder\n",
    "\n",
    "taxi_parquet_url = find_taxi_parquet_urls()\n",
    "download_taxi_data(taxi_parquet_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bfe8b834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 211;\n",
       "                var nbb_unformatted_code = \"columns_needed1 = [\\n    \\\"Trip_Pickup_DateTime\\\",\\n    \\\"Trip_Dropoff_DateTime\\\",\\n    \\\"Start_Lon\\\",\\n    \\\"Start_Lat\\\",\\n    \\\"End_Lon\\\",\\n    \\\"End_Lat\\\",\\n    \\\"Tip_Amt\\\"]\\n\\ncolumns_needed2 = [\\n    \\\"tpep_pickup_datetime\\\",\\n    \\\"tpep_dropoff_datetime\\\",\\n    \\\"PULocationID\\\",\\n    \\\"DOLocationID\\\",\\n    \\\"tip_amount\\\"]\\n\\ncolumns_needed3 = [\\n    \\\"pickup_datetime\\\",\\n    \\\"dropoff_datetime\\\",\\n    \\\"pickup_longitude\\\",\\n    \\\"pickup_latitude\\\",\\n    \\\"dropoff_longitude\\\",\\n    \\\"dropoff_latitude\\\",\\n    \\\"tip_amount\\\"]\\n\\ntest = pd.read_parquet(\\\"yellow_tripdata_2014-02.parquet\\\")\\n\\n\\ntest.columns\";\n",
       "                var nbb_formatted_code = \"columns_needed1 = [\\n    \\\"Trip_Pickup_DateTime\\\",\\n    \\\"Trip_Dropoff_DateTime\\\",\\n    \\\"Start_Lon\\\",\\n    \\\"Start_Lat\\\",\\n    \\\"End_Lon\\\",\\n    \\\"End_Lat\\\",\\n    \\\"Tip_Amt\\\",\\n]\\n\\ncolumns_needed2 = [\\n    \\\"tpep_pickup_datetime\\\",\\n    \\\"tpep_dropoff_datetime\\\",\\n    \\\"PULocationID\\\",\\n    \\\"DOLocationID\\\",\\n    \\\"tip_amount\\\",\\n]\\n\\ncolumns_needed3 = [\\n    \\\"pickup_datetime\\\",\\n    \\\"dropoff_datetime\\\",\\n    \\\"pickup_longitude\\\",\\n    \\\"pickup_latitude\\\",\\n    \\\"dropoff_longitude\\\",\\n    \\\"dropoff_latitude\\\",\\n    \\\"tip_amount\\\",\\n]\\n\\ntest = pd.read_parquet(\\\"yellow_tripdata_2014-02.parquet\\\")\\n\\n\\ntest.columns\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_needed1 = [\n",
    "    \"Trip_Pickup_DateTime\",\n",
    "    \"Trip_Dropoff_DateTime\",\n",
    "    \"Start_Lon\",\n",
    "    \"Start_Lat\",\n",
    "    \"End_Lon\",\n",
    "    \"End_Lat\",\n",
    "    \"Tip_Amt\",\n",
    "]\n",
    "\n",
    "columns_needed2 = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"tip_amount\",\n",
    "]\n",
    "\n",
    "columns_needed3 = [\n",
    "    \"pickup_datetime\",\n",
    "    \"dropoff_datetime\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"tip_amount\",\n",
    "]\n",
    "\n",
    "test = pd.read_parquet(\"yellow_tripdata_2014-02.parquet\")\n",
    "\n",
    "\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5f93715c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:30:05</td>\n",
       "      <td>2014-02-01 00:30:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:16:52</td>\n",
       "      <td>2014-02-01 00:18:22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:05:03</td>\n",
       "      <td>2014-02-01 00:15:44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:17:19</td>\n",
       "      <td>2014-02-01 00:20:15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-01 00:24:08</td>\n",
       "      <td>2014-02-01 00:37:07</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2014-02-01 00:30:05   2014-02-01 00:30:17                1   \n",
       "1         1  2014-02-01 00:16:52   2014-02-01 00:18:22                1   \n",
       "2         1  2014-02-01 00:05:03   2014-02-01 00:15:44                1   \n",
       "3         1  2014-02-01 00:17:19   2014-02-01 00:20:15                1   \n",
       "4         1  2014-02-01 00:24:08   2014-02-01 00:37:07                2   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            0.0           1                  N           140           140   \n",
       "1            0.0           1                  N           186           186   \n",
       "2            2.0           1                  N           107           249   \n",
       "3            0.7           1                  N           158            90   \n",
       "4            2.4           1                  N           234           246   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          2.5    0.5      0.5         0.0           0.0   \n",
       "1             2          3.0    0.5      0.5         0.0           0.0   \n",
       "2             1          9.5    0.5      0.5         2.1           0.0   \n",
       "3             1          4.5    0.5      0.5         1.5           0.0   \n",
       "4             1         11.5    0.5      0.5         2.5           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount congestion_surcharge airport_fee  \n",
       "0                    0.0           3.5                 None        None  \n",
       "1                    0.0           4.0                 None        None  \n",
       "2                    0.0          12.6                 None        None  \n",
       "3                    0.0           7.0                 None        None  \n",
       "4                    0.0          15.0                 None        None  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 156;\n",
       "                var nbb_unformatted_code = \"test.head()\";\n",
       "                var nbb_formatted_code = \"test.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "717377c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 169;\n",
       "                var nbb_unformatted_code = \"gdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n\\ndef convert_locationId(locationId):\\n\\n    geo_row = gdf.loc[gdf[\\\"LocationID\\\"] == locationId]\\n    lon = geo_row[\\\"geometry\\\"].centroid.x.tolist()[0]\\n    lat = geo_row[\\\"geometry\\\"].centroid.y.tolist()[0]\\n\\n    return (lat, lon)\";\n",
       "                var nbb_formatted_code = \"gdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n\\n\\ndef convert_locationId(locationId):\\n\\n    geo_row = gdf.loc[gdf[\\\"LocationID\\\"] == locationId]\\n    lon = geo_row[\\\"geometry\\\"].centroid.x.tolist()[0]\\n    lat = geo_row[\\\"geometry\\\"].centroid.y.tolist()[0]\\n\\n    return (lat, lon)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def convert_geometry(locationId):\n",
    "\n",
    "#     geo_row = gdf.loc[gdf[\"LocationID\"] == locationId]\n",
    "#     lon = geo_row[\"geometry\"].centroid.x.tolist()[0]\n",
    "#     lat = geo_row[\"geometry\"].centroid.y.tolist()[0]\n",
    "\n",
    "#     return (lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb06a7",
   "metadata": {},
   "source": [
    "### Load taxi zones shp file and convert the polygon to coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "443e0be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 332;\n",
       "                var nbb_unformatted_code = \"def convert_geometry(polygon):\\n    \\\"\\\"\\\"Conver polygon to its center point\\n\\n    Args:\\n        polygon (Polygon): shapely.geometry.polygon.Polygon type\\n\\n    Returns:\\n        tuple: Contain the latitude and longitude values\\n\\n    \\\"\\\"\\\"\\n    lon = polygon.centroid.x\\n    lat = polygon.centroid.y\\n    return (lat, lon)\\n\\n\\ngdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# gdf[\\\"center_lon\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.x)\\n# gdf[\\\"center_lat\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.y)\\ngdf[\\\"location_coordinate\\\"] = gdf[\\\"geometry\\\"].apply(convert_geometry)\\n\\n# Only keep the ID and coordinate columns\\ngdf = gdf[[\\\"LocationID\\\", \\\"location_coordinate\\\"]]\\n\\n# Remove duplicate LocationID: 56 and 103\\ngdf = gdf[~gdf[\\\"LocationID\\\"].duplicated(keep=False)]\";\n",
       "                var nbb_formatted_code = \"def convert_geometry(polygon):\\n    \\\"\\\"\\\"Conver polygon to its center point\\n\\n    Args:\\n        polygon (Polygon): shapely.geometry.polygon.Polygon type\\n\\n    Returns:\\n        tuple: Contain the latitude and longitude values\\n\\n    \\\"\\\"\\\"\\n    lon = polygon.centroid.x\\n    lat = polygon.centroid.y\\n    return (lat, lon)\\n\\n\\ngdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# gdf[\\\"center_lon\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.x)\\n# gdf[\\\"center_lat\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.y)\\ngdf[\\\"location_coordinate\\\"] = gdf[\\\"geometry\\\"].apply(convert_geometry)\\n\\n# Only keep the ID and coordinate columns\\ngdf = gdf[[\\\"LocationID\\\", \\\"location_coordinate\\\"]]\\n\\n# Remove duplicate LocationID: 56 and 103\\ngdf = gdf[~gdf[\\\"LocationID\\\"].duplicated(keep=False)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_geometry(polygon):\n",
    "    \"\"\"Conver polygon to its center point\n",
    "\n",
    "    Args:\n",
    "        polygon (Polygon): shapely.geometry.polygon.Polygon type\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contain the latitude and longitude values\n",
    "\n",
    "    \"\"\"\n",
    "    lon = polygon.centroid.x\n",
    "    lat = polygon.centroid.y\n",
    "    return (lat, lon)\n",
    "\n",
    "\n",
    "gdf = geopandas.read_file(\"taxi_zones/taxi_zones.shp\").to_crs(4326)\n",
    "# gdf[\"center_lon\"] = gdf[\"geometry\"].apply(lambda p: p.centroid.x)\n",
    "# gdf[\"center_lat\"] = gdf[\"geometry\"].apply(lambda p: p.centroid.y)\n",
    "gdf[\"location_coordinate\"] = gdf[\"geometry\"].apply(convert_geometry)\n",
    "\n",
    "# Only keep the ID and coordinate columns\n",
    "gdf = gdf[[\"LocationID\", \"location_coordinate\"]]\n",
    "\n",
    "# Remove duplicate LocationID: 56 and 103\n",
    "gdf = gdf[~gdf[\"LocationID\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b6ad964a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y  Z\n",
      "0  0  0  0\n",
      "1  1  2  3\n",
      "2  2  2  2\n",
      "3  3  2  1\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 358;\n",
       "                var nbb_unformatted_code = \"from shapely.geometry import Polygon, Point\\n\\ndf = pd.DataFrame([[0, 0, 0], [1, 2, 3], [2, 2, 2], [3, 2, 1] ], columns = list(\\\"XYZ\\\"))\\n#your polygon points\\npolygon1_list = [(1, 1), (1, 3), (3, 3), (3, 1)]\\n#adding a column that contains a boolean variable for each point\\ndf[\\\"polygon1\\\"] = df.apply(lambda row: Polygon(polygon1_list).contains(Point(row[\\\"X\\\"], row[\\\"Y\\\"])), axis = 1)\\nprint(df)\";\n",
       "                var nbb_formatted_code = \"from shapely.geometry import Polygon, Point\\n\\ndf = pd.DataFrame([[0, 0, 0], [1, 2, 3], [2, 2, 2], [3, 2, 1]], columns=list(\\\"XYZ\\\"))\\n# your polygon points\\npolygon1_list = [(1, 1), (1, 3), (3, 3), (3, 1)]\\n# adding a column that contains a boolean variable for each point\\ndf[\\\"polygon1\\\"] = df.apply(\\n    lambda row: Polygon(polygon1_list).contains(Point(row[\\\"X\\\"], row[\\\"Y\\\"])), axis=1\\n)\\nprint(df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-01 00:05:03</td>\n",
       "      <td>2014-02-01 00:15:44</td>\n",
       "      <td>2.1</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.734575</td>\n",
       "      <td>-74.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-01 00:17:19</td>\n",
       "      <td>2014-02-01 00:20:15</td>\n",
       "      <td>1.5</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>40.742278</td>\n",
       "      <td>-73.996971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01 00:24:08</td>\n",
       "      <td>2014-02-01 00:37:07</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-01 00:00:23</td>\n",
       "      <td>2014-02-01 00:09:26</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-01 00:18:58</td>\n",
       "      <td>2014-02-01 00:22:34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.756687</td>\n",
       "      <td>-73.972356</td>\n",
       "      <td>40.766948</td>\n",
       "      <td>-73.959635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197578</th>\n",
       "      <td>2014-02-28 23:39:00</td>\n",
       "      <td>2014-02-28 23:45:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.985937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197579</th>\n",
       "      <td>2014-02-28 23:48:00</td>\n",
       "      <td>2014-03-01 00:01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.728340</td>\n",
       "      <td>-73.997380</td>\n",
       "      <td>40.742278</td>\n",
       "      <td>-73.996971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197580</th>\n",
       "      <td>2014-02-28 23:15:00</td>\n",
       "      <td>2014-02-28 23:38:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.717772</td>\n",
       "      <td>-74.007880</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197581</th>\n",
       "      <td>2014-02-28 23:53:00</td>\n",
       "      <td>2014-03-01 00:12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.688168</td>\n",
       "      <td>-73.931888</td>\n",
       "      <td>40.676644</td>\n",
       "      <td>-73.913632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197582</th>\n",
       "      <td>2014-02-28 23:12:00</td>\n",
       "      <td>2014-02-28 23:29:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.670374</td>\n",
       "      <td>-73.981414</td>\n",
       "      <td>40.644288</td>\n",
       "      <td>-73.937966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12197583 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime    dropoff_datetime  tip_amount  pickup_latitude  \\\n",
       "0        2014-02-01 00:05:03 2014-02-01 00:15:44         2.1        40.736824   \n",
       "1        2014-02-01 00:17:19 2014-02-01 00:20:15         1.5        40.735035   \n",
       "2        2014-02-01 00:24:08 2014-02-01 00:37:07         2.5        40.740337   \n",
       "3        2014-02-01 00:00:23 2014-02-01 00:09:26         2.5        40.736824   \n",
       "4        2014-02-01 00:18:58 2014-02-01 00:22:34         0.0        40.756687   \n",
       "...                      ...                 ...         ...              ...   \n",
       "12197578 2014-02-28 23:39:00 2014-02-28 23:45:00         1.2        40.723752   \n",
       "12197579 2014-02-28 23:48:00 2014-03-01 00:01:00         1.0        40.728340   \n",
       "12197580 2014-02-28 23:15:00 2014-02-28 23:38:00         4.0        40.717772   \n",
       "12197581 2014-02-28 23:53:00 2014-03-01 00:12:00         0.0        40.688168   \n",
       "12197582 2014-02-28 23:12:00 2014-02-28 23:29:00         0.0        40.670374   \n",
       "\n",
       "          pickup_longitude  dropoff_latitude  dropoff_longitude  \n",
       "0               -73.984052         40.734575         -74.002875  \n",
       "1               -74.008984         40.742278         -73.996971  \n",
       "2               -73.990458         40.753309         -74.004015  \n",
       "3               -73.984052         40.765484         -73.954739  \n",
       "4               -73.972356         40.766948         -73.959635  \n",
       "...                    ...               ...                ...  \n",
       "12197578        -73.976968         40.727620         -73.985937  \n",
       "12197579        -73.997380         40.742278         -73.996971  \n",
       "12197580        -74.007880         40.674469         -73.939287  \n",
       "12197581        -73.931888         40.676644         -73.913632  \n",
       "12197582        -73.981414         40.644288         -73.937966  \n",
       "\n",
       "[12197583 rows x 7 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 352;\n",
       "                var nbb_unformatted_code = \"def clean_taxi_data_with_id(df):\\n    # Keep only the columns that matters\\n    df = df[\\n        [\\n            \\\"tpep_pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\",\\n            \\\"PULocationID\\\",\\n            \\\"DOLocationID\\\",\\n            \\\"tip_amount\\\",\\n        ]\\n    ]\\n    # Drop rows where pickup location ID is the same as drop-off\\n    df = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\n    \\n    # Convert LocationID to coordinate\\n    df[\\\"pickup_location\\\"] = df[\\\"PULocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    df[\\\"dropoff_location\\\"] = df[\\\"DOLocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    # Split the coordinate into latitude and longitude\\n    df[[\\\"pickup_latitude\\\", \\\"pickup_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"pickup_location\\\"].tolist(), index=df.index\\n    )\\n    df[[\\\"dropoff_latitude\\\", \\\"dropoff_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"dropoff_location\\\"].tolist(), index=df.index\\n    )\\n    \\n    # Drop LocationID columns\\n    df = df.drop(\\n        columns=[\\\"PULocationID\\\", \\\"DOLocationID\\\", \\\"pickup_location\\\", \\\"dropoff_location\\\"]\\n    ).reset_index(drop=True)\\n    \\n    # Normalize column names\\n    df = df.rename(columns={\\\"tpep_pickup_datetime\\\": \\\"pickup_datetime\\\", \\\"tpep_dropoff_datetime\\\": \\\"dropoff_datetime\\\"})\\n    \\n    return df\\n\\n\\ndef get_and_clean_month_taxi_data(url):\\n    response = requests.get(url, stream=True)\\n    file_name = url.split(\\\"/\\\")[-1]\\n\\n    with open(file_name, \\\"wb\\\") as f:\\n        for chunk in response.iter_content(chunk_size=1024):\\n            if chunk:\\n                f.write(chunk)\\n\\n    df = pd.read_parquet(file_name)\\n\\n    # There are three dataset types for taxi data\\n    # 1. Has location ID\\n    if \\\"PULocationID\\\" in df.columns:\\n       df = clean_taxi_data_with_id(df)\\n        \\n        \\n    # 2. Column name with \\\"Start_Lon\\\", \\\"Start_Lat\\\", \\\"End_Lon\\\", \\\"End_Lat\\\"\\n#     if \\\"Start_Lon\\\" in df.columns:\\n        \\n\\n# find_taxi_parquet_urls()[0]\\n# get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet')\";\n",
       "                var nbb_formatted_code = \"def clean_taxi_data_with_id(df):\\n    # Keep only the columns that matters\\n    df = df[\\n        [\\n            \\\"tpep_pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\",\\n            \\\"PULocationID\\\",\\n            \\\"DOLocationID\\\",\\n            \\\"tip_amount\\\",\\n        ]\\n    ]\\n    # Drop rows where pickup location ID is the same as drop-off\\n    df = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\n\\n    # Convert LocationID to coordinate\\n    df[\\\"pickup_location\\\"] = df[\\\"PULocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    df[\\\"dropoff_location\\\"] = df[\\\"DOLocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    # Split the coordinate into latitude and longitude\\n    df[[\\\"pickup_latitude\\\", \\\"pickup_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"pickup_location\\\"].tolist(), index=df.index\\n    )\\n    df[[\\\"dropoff_latitude\\\", \\\"dropoff_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"dropoff_location\\\"].tolist(), index=df.index\\n    )\\n\\n    # Drop LocationID columns\\n    df = df.drop(\\n        columns=[\\\"PULocationID\\\", \\\"DOLocationID\\\", \\\"pickup_location\\\", \\\"dropoff_location\\\"]\\n    ).reset_index(drop=True)\\n\\n    # Normalize column names\\n    df = df.rename(\\n        columns={\\n            \\\"tpep_pickup_datetime\\\": \\\"pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\": \\\"dropoff_datetime\\\",\\n        }\\n    )\\n\\n    return df\\n\\n\\ndef get_and_clean_month_taxi_data(url):\\n    response = requests.get(url, stream=True)\\n    file_name = url.split(\\\"/\\\")[-1]\\n\\n    with open(file_name, \\\"wb\\\") as f:\\n        for chunk in response.iter_content(chunk_size=1024):\\n            if chunk:\\n                f.write(chunk)\\n\\n    df = pd.read_parquet(file_name)\\n\\n    # There are three dataset types for taxi data\\n    # 1. Has location ID\\n    if \\\"PULocationID\\\" in df.columns:\\n        df = clean_taxi_data_with_id(df)\\n\\n    # 2. Column name with \\\"Start_Lon\\\", \\\"Start_Lat\\\", \\\"End_Lon\\\", \\\"End_Lat\\\"\\n\\n\\n#     if \\\"Start_Lon\\\" in df.columns:\\n\\n\\n# find_taxi_parquet_urls()[0]\\n# get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet')\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_taxi_data_with_locationId(df):\n",
    "    # Keep only the columns that matters\n",
    "    df = df[\n",
    "        [\n",
    "            \"tpep_pickup_datetime\",\n",
    "            \"tpep_dropoff_datetime\",\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"tip_amount\",\n",
    "        ]\n",
    "    ]\n",
    "    # Drop rows where pickup location ID is the same as drop-off\n",
    "    df = df[df[\"PULocationID\"] != df[\"DOLocationID\"]]\n",
    "    \n",
    "    # Convert LocationID to coordinate\n",
    "    df[\"pickup_location\"] = df[\"PULocationID\"].map(\n",
    "        gdf.set_index(\"LocationID\")[\"location_coordinate\"]\n",
    "    )\n",
    "    df[\"dropoff_location\"] = df[\"DOLocationID\"].map(\n",
    "        gdf.set_index(\"LocationID\")[\"location_coordinate\"]\n",
    "    )\n",
    "    # Split the coordinate into latitude and longitude\n",
    "    df[[\"pickup_latitude\", \"pickup_longitude\"]] = pd.DataFrame(\n",
    "        df[\"pickup_location\"].tolist(), index=df.index\n",
    "    )\n",
    "    df[[\"dropoff_latitude\", \"dropoff_longitude\"]] = pd.DataFrame(\n",
    "        df[\"dropoff_location\"].tolist(), index=df.index\n",
    "    )\n",
    "    \n",
    "    # Drop LocationID columns\n",
    "    df = df.drop(\n",
    "        columns=[\"PULocationID\", \"DOLocationID\", \"pickup_location\", \"dropoff_location\"]\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    # Normalize column names\n",
    "    df = df.rename(columns={\"tpep_pickup_datetime\": \"pickup_datetime\", \"tpep_dropoff_datetime\": \"dropoff_datetime\"})\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_and_clean_month_taxi_data(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    df = pd.read_parquet(file_name)\n",
    "\n",
    "    # There are three dataset types for taxi data\n",
    "    # 1. Has location ID\n",
    "    if \"PULocationID\" in df.columns:\n",
    "        df = clean_taxi_data_with_locationId(df)\n",
    "        \n",
    "      \n",
    "    # 2. Column name with \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\"\n",
    "    elif \"Start_Lon\" in df.columns:\n",
    "        \n",
    "\n",
    "# find_taxi_parquet_urls()[0]\n",
    "get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cb2b5493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-01 00:05:03</td>\n",
       "      <td>2014-02-01 00:15:44</td>\n",
       "      <td>2.1</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.734575</td>\n",
       "      <td>-74.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-01 00:17:19</td>\n",
       "      <td>2014-02-01 00:20:15</td>\n",
       "      <td>1.5</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>40.742278</td>\n",
       "      <td>-73.996971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01 00:24:08</td>\n",
       "      <td>2014-02-01 00:37:07</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-02-01 00:00:23</td>\n",
       "      <td>2014-02-01 00:09:26</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.736824</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.765484</td>\n",
       "      <td>-73.954739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-02-01 00:18:58</td>\n",
       "      <td>2014-02-01 00:22:34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.756687</td>\n",
       "      <td>-73.972356</td>\n",
       "      <td>40.766948</td>\n",
       "      <td>-73.959635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197578</th>\n",
       "      <td>2014-02-28 23:39:00</td>\n",
       "      <td>2014-02-28 23:45:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>40.723752</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.985937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197579</th>\n",
       "      <td>2014-02-28 23:48:00</td>\n",
       "      <td>2014-03-01 00:01:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.728340</td>\n",
       "      <td>-73.997380</td>\n",
       "      <td>40.742278</td>\n",
       "      <td>-73.996971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197580</th>\n",
       "      <td>2014-02-28 23:15:00</td>\n",
       "      <td>2014-02-28 23:38:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.717772</td>\n",
       "      <td>-74.007880</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197581</th>\n",
       "      <td>2014-02-28 23:53:00</td>\n",
       "      <td>2014-03-01 00:12:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.688168</td>\n",
       "      <td>-73.931888</td>\n",
       "      <td>40.676644</td>\n",
       "      <td>-73.913632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197582</th>\n",
       "      <td>2014-02-28 23:12:00</td>\n",
       "      <td>2014-02-28 23:29:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.670374</td>\n",
       "      <td>-73.981414</td>\n",
       "      <td>40.644288</td>\n",
       "      <td>-73.937966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12197583 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime    dropoff_datetime  tip_amount  pickup_latitude  \\\n",
       "0        2014-02-01 00:05:03 2014-02-01 00:15:44         2.1        40.736824   \n",
       "1        2014-02-01 00:17:19 2014-02-01 00:20:15         1.5        40.735035   \n",
       "2        2014-02-01 00:24:08 2014-02-01 00:37:07         2.5        40.740337   \n",
       "3        2014-02-01 00:00:23 2014-02-01 00:09:26         2.5        40.736824   \n",
       "4        2014-02-01 00:18:58 2014-02-01 00:22:34         0.0        40.756687   \n",
       "...                      ...                 ...         ...              ...   \n",
       "12197578 2014-02-28 23:39:00 2014-02-28 23:45:00         1.2        40.723752   \n",
       "12197579 2014-02-28 23:48:00 2014-03-01 00:01:00         1.0        40.728340   \n",
       "12197580 2014-02-28 23:15:00 2014-02-28 23:38:00         4.0        40.717772   \n",
       "12197581 2014-02-28 23:53:00 2014-03-01 00:12:00         0.0        40.688168   \n",
       "12197582 2014-02-28 23:12:00 2014-02-28 23:29:00         0.0        40.670374   \n",
       "\n",
       "          pickup_longitude  dropoff_latitude  dropoff_longitude  \n",
       "0               -73.984052         40.734575         -74.002875  \n",
       "1               -74.008984         40.742278         -73.996971  \n",
       "2               -73.990458         40.753309         -74.004015  \n",
       "3               -73.984052         40.765484         -73.954739  \n",
       "4               -73.972356         40.766948         -73.959635  \n",
       "...                    ...               ...                ...  \n",
       "12197578        -73.976968         40.727620         -73.985937  \n",
       "12197579        -73.997380         40.742278         -73.996971  \n",
       "12197580        -74.007880         40.674469         -73.939287  \n",
       "12197581        -73.931888         40.676644         -73.913632  \n",
       "12197582        -73.981414         40.644288         -73.937966  \n",
       "\n",
       "[12197583 rows x 7 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 361;\n",
       "                var nbb_unformatted_code = \"from shapely.geometry import Polygon, Point\\n\\n# df = pd.DataFrame([[0, 0, 0], [1, 2, 3], [2, 2, 2], [3, 2, 1] ], columns = list(\\\"XYZ\\\"))\\n#your polygon points\\npolygon1_list = [(40.560445, -74.242330), (40.908524, -73.717047)]\\n# #adding a column that contains a boolean variable for each point\\ndf[\\\"polygon1\\\"] = df.apply(lambda row: Polygon(polygon1_list).contains(Point(row[\\\"pickup_latitude\\\"], row[\\\"pickup_longitude\\\"])), axis = 1)\\ndf\\n\\n# Test geopandas pacakge\\n\\n# gdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# lon = gdf[\\\"geometry\\\"][0].centroid.x\\n# lat = gdf[\\\"geometry\\\"][0].centroid.y\\n\\n\\n# calculate_distance(df[\\\"pickup_location\\\"][0], df[\\\"dropoff_location\\\"][0])\\n# type(df[\\\"pickup_location\\\"][0])\";\n",
       "                var nbb_formatted_code = \"from shapely.geometry import Polygon, Point\\n\\n# df = pd.DataFrame([[0, 0, 0], [1, 2, 3], [2, 2, 2], [3, 2, 1] ], columns = list(\\\"XYZ\\\"))\\n# your polygon points\\npolygon1_list = [(40.560445, -74.242330), (40.908524, -73.717047)]\\n# #adding a column that contains a boolean variable for each point\\ndf[\\\"polygon1\\\"] = df.apply(\\n    lambda row: Polygon(polygon1_list).contains(\\n        Point(row[\\\"pickup_latitude\\\"], row[\\\"pickup_longitude\\\"])\\n    ),\\n    axis=1,\\n)\\ndf\\n\\n# Test geopandas pacakge\\n\\n# gdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# lon = gdf[\\\"geometry\\\"][0].centroid.x\\n# lat = gdf[\\\"geometry\\\"][0].centroid.y\\n\\n\\n# calculate_distance(df[\\\"pickup_location\\\"][0], df[\\\"dropoff_location\\\"][0])\\n# type(df[\\\"pickup_location\\\"][0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_new = df[df[\"PULocationID\"] != df[\"DOLocationID\"]]\n",
    "# len(df_new)\n",
    "\n",
    "df = pd.read_parquet(\"yellow_tripdata_2014-02.parquet\")\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        \"tpep_pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"tip_amount\",\n",
    "    ]\n",
    "]\n",
    "df = df[df[\"PULocationID\"] != df[\"DOLocationID\"]]\n",
    "df[\"pickup_location\"] = df[\"PULocationID\"].map(\n",
    "    gdf.set_index(\"LocationID\")[\"location_coordinate\"]\n",
    ")\n",
    "df[\"dropoff_location\"] = df[\"DOLocationID\"].map(\n",
    "    gdf.set_index(\"LocationID\")[\"location_coordinate\"]\n",
    ")\n",
    "\n",
    "df[[\"pickup_latitude\", \"pickup_longitude\"]] = pd.DataFrame(\n",
    "    df[\"pickup_location\"].tolist(), index=df.index\n",
    ")\n",
    "df[[\"dropoff_latitude\", \"dropoff_longitude\"]] = pd.DataFrame(\n",
    "    df[\"dropoff_location\"].tolist(), index=df.index\n",
    ")\n",
    "\n",
    "df = df.drop(\n",
    "    columns=[\"PULocationID\", \"DOLocationID\", \"pickup_location\", \"dropoff_location\"]\n",
    ").reset_index(drop=True)\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1fbdd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 354;\n",
       "                var nbb_unformatted_code = \"# df_new = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\n# len(df_new)\\n\\ndf = pd.read_parquet(\\\"yellow_tripdata_2014-02.parquet\\\")\\n\\ndf = df[\\n    [\\n        \\\"tpep_pickup_datetime\\\",\\n        \\\"tpep_dropoff_datetime\\\",\\n        \\\"PULocationID\\\",\\n        \\\"DOLocationID\\\",\\n        \\\"tip_amount\\\",\\n    ]\\n]\\ndf = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\ndf[\\\"pickup_location\\\"] = df[\\\"PULocationID\\\"].map(\\n    gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n)\\ndf[\\\"dropoff_location\\\"] = df[\\\"DOLocationID\\\"].map(\\n    gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n)\\n\\ndf[[\\\"pickup_latitude\\\", \\\"pickup_longitude\\\"]] = pd.DataFrame(\\n    df[\\\"pickup_location\\\"].tolist(), index=df.index\\n)\\ndf[[\\\"dropoff_latitude\\\", \\\"dropoff_longitude\\\"]] = pd.DataFrame(\\n    df[\\\"dropoff_location\\\"].tolist(), index=df.index\\n)\\n\\ndf = df.drop(\\n    columns=[\\\"PULocationID\\\", \\\"DOLocationID\\\", \\\"pickup_location\\\", \\\"dropoff_location\\\"]\\n).reset_index(drop=True)\\ndf = df.rename(\\n    columns={\\n        \\\"tpep_pickup_datetime\\\": \\\"pickup_datetime\\\",\\n        \\\"tpep_dropoff_datetime\\\": \\\"dropoff_datetime\\\",\\n    }\\n)\\ndf\";\n",
       "                var nbb_formatted_code = \"# df_new = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\n# len(df_new)\\n\\ndf = pd.read_parquet(\\\"yellow_tripdata_2014-02.parquet\\\")\\n\\ndf = df[\\n    [\\n        \\\"tpep_pickup_datetime\\\",\\n        \\\"tpep_dropoff_datetime\\\",\\n        \\\"PULocationID\\\",\\n        \\\"DOLocationID\\\",\\n        \\\"tip_amount\\\",\\n    ]\\n]\\ndf = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\ndf[\\\"pickup_location\\\"] = df[\\\"PULocationID\\\"].map(\\n    gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n)\\ndf[\\\"dropoff_location\\\"] = df[\\\"DOLocationID\\\"].map(\\n    gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n)\\n\\ndf[[\\\"pickup_latitude\\\", \\\"pickup_longitude\\\"]] = pd.DataFrame(\\n    df[\\\"pickup_location\\\"].tolist(), index=df.index\\n)\\ndf[[\\\"dropoff_latitude\\\", \\\"dropoff_longitude\\\"]] = pd.DataFrame(\\n    df[\\\"dropoff_location\\\"].tolist(), index=df.index\\n)\\n\\ndf = df.drop(\\n    columns=[\\\"PULocationID\\\", \\\"DOLocationID\\\", \\\"pickup_location\\\", \\\"dropoff_location\\\"]\\n).reset_index(drop=True)\\ndf = df.rename(\\n    columns={\\n        \\\"tpep_pickup_datetime\\\": \\\"pickup_datetime\\\",\\n        \\\"tpep_dropoff_datetime\\\": \\\"dropoff_datetime\\\",\\n    }\\n)\\ndf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df[\"pickup_location\"].str[1]\n",
    "\n",
    "gdf_taxi = geopandas.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=geopandas.points_from_xy(df.pickup_longitude, df.pickup_latitude),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "dd8d0faf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A LinearRing must have at least 3 coordinate tuples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/shapely/speedups/_speedups.pyx:252\u001b[0m, in \u001b[0;36mshapely.speedups._speedups.geos_linearring_from_py\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute '__array_interface__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[361], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m polygon1_list \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m40.560445\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m74.242330\u001b[39m), (\u001b[38;5;241m40.908524\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m73.717047\u001b[39m)]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# #adding a column that contains a boolean variable for each point\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolygon1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPolygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon1_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickup_latitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickup_longitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m df\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Test geopandas pacakge\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# gdf = geopandas.read_file(\"taxi_zones/taxi_zones.shp\").to_crs(4326)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# calculate_distance(df[\"pickup_location\"][0], df[\"dropoff_location\"][0])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# type(df[\"pickup_location\"][0])\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/pandas/core/frame.py:9565\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9554\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9556\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9558\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9563\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9564\u001b[0m )\n\u001b[0;32m-> 9565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/pandas/core/apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 873\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/pandas/core/apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    891\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    892\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    893\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[361], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      5\u001b[0m polygon1_list \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m40.560445\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m74.242330\u001b[39m), (\u001b[38;5;241m40.908524\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m73.717047\u001b[39m)]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# #adding a column that contains a boolean variable for each point\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolygon1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mPolygon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygon1_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontains(Point(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_latitude\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickup_longitude\u001b[39m\u001b[38;5;124m\"\u001b[39m])), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m df\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Test geopandas pacakge\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# gdf = geopandas.read_file(\"taxi_zones/taxi_zones.shp\").to_crs(4326)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# calculate_distance(df[\"pickup_location\"][0], df[\"dropoff_location\"][0])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# type(df[\"pickup_location\"][0])\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/shapely/geometry/polygon.py:261\u001b[0m, in \u001b[0;36mPolygon.__init__\u001b[0;34m(self, shell, holes)\u001b[0m\n\u001b[1;32m    258\u001b[0m BaseGeometry\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mgeos_polygon_from_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m         geom, n \u001b[38;5;241m=\u001b[39m ret\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/shapely/geometry/polygon.py:539\u001b[0m, in \u001b[0;36mgeos_polygon_from_py\u001b[0;34m(shell, holes)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m geos_geom_from_py(shell)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mgeos_linearring_from_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/geo_env/lib/python3.10/site-packages/shapely/speedups/_speedups.pyx:346\u001b[0m, in \u001b[0;36mshapely.speedups._speedups.geos_linearring_from_py\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A LinearRing must have at least 3 coordinate tuples"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 360;\n",
       "                var nbb_unformatted_code = \"gdf_taxi\\n\\n# Test geopandas pacakge\\n\\n# gdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# lon = gdf[\\\"geometry\\\"][0].centroid.x\\n# lat = gdf[\\\"geometry\\\"][0].centroid.y\\n\\n\\n# calculate_distance(df[\\\"pickup_location\\\"][0], df[\\\"dropoff_location\\\"][0])\\n# type(df[\\\"pickup_location\\\"][0])\";\n",
       "                var nbb_formatted_code = \"gdf_taxi\\n\\n# Test geopandas pacakge\\n\\n# gdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# lon = gdf[\\\"geometry\\\"][0].centroid.x\\n# lat = gdf[\\\"geometry\\\"][0].centroid.y\\n\\n\\n# calculate_distance(df[\\\"pickup_location\\\"][0], df[\\\"dropoff_location\\\"][0])\\n# type(df[\\\"pickup_location\\\"][0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "# df = pd.DataFrame([[0, 0, 0], [1, 2, 3], [2, 2, 2], [3, 2, 1] ], columns = list(\"XYZ\"))\n",
    "# your polygon points\n",
    "polygon1_list = [(40.560445, -74.242330), (40.908524, -73.717047)]\n",
    "# #adding a column that contains a boolean variable for each point\n",
    "df[\"polygon1\"] = df.apply(\n",
    "    lambda row: Polygon(polygon1_list).contains(\n",
    "        Point(row[\"pickup_latitude\"], row[\"pickup_longitude\"])\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df\n",
    "\n",
    "# Test geopandas pacakge\n",
    "\n",
    "# gdf = geopandas.read_file(\"taxi_zones/taxi_zones.shp\").to_crs(4326)\n",
    "# lon = gdf[\"geometry\"][0].centroid.x\n",
    "# lat = gdf[\"geometry\"][0].centroid.y\n",
    "\n",
    "\n",
    "# calculate_distance(df[\"pickup_location\"][0], df[\"dropoff_location\"][0])\n",
    "# type(df[\"pickup_location\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"def get_and_clean_taxi_data():\\n    all_taxi_dataframes = []\\n    \\n    all_csv_urls = find_taxi_csv_urls()\\n    for csv_url in all_csv_url:\\n        # maybe: first try to see if you've downloaded this exact\\n        # file already and saved it before trying again\\n        dataframe = get_and_clean_month_taxi_data(csv_url)\\n        add_distance_column(dataframe)\\n        # maybe: if the file hasn't been saved, save it so you can\\n        # avoid re-downloading it if you re-run the function\\n        \\n        all_taxi_dataframes.append(dataframe)\\n        \\n    # create one gigantic dataframe with data from every month needed\\n    taxi_data = pd.contact(all_taxi_dataframes)\\n    return taxi_data\";\n",
       "                var nbb_formatted_code = \"def get_and_clean_taxi_data():\\n    all_taxi_dataframes = []\\n\\n    all_csv_urls = find_taxi_csv_urls()\\n    for csv_url in all_csv_url:\\n        # maybe: first try to see if you've downloaded this exact\\n        # file already and saved it before trying again\\n        dataframe = get_and_clean_month_taxi_data(csv_url)\\n        add_distance_column(dataframe)\\n        # maybe: if the file hasn't been saved, save it so you can\\n        # avoid re-downloading it if you re-run the function\\n\\n        all_taxi_dataframes.append(dataframe)\\n\\n    # create one gigantic dataframe with data from every month needed\\n    taxi_data = pd.contact(all_taxi_dataframes)\\n    return taxi_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "\n",
    "    all_csv_urls = find_taxi_csv_urls()\n",
    "    for csv_url in all_csv_url:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        add_distance_column(dataframe)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "\n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.contact(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\"TODO\"]\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_N = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_N).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_N, \"some_descriptive_name.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
