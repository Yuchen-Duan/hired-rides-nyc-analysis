{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sqlalchemy as db\n",
    "import logging\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, DateTime, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# notebook formatting\\n\\n%load_ext nb_black\\n# %reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# notebook formatting\\n\\n%load_ext nb_black\\n# %reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# notebook formatting\n",
    "\n",
    "%load_ext nb_black\n",
    "# %reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# any constants you might need, for example:\\n\\nTAXI_URL = \\\"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\\\"\\n# add other constants to refer to any local data, e.g. uber & weather\\nUBER_CSV = \\\"uber_rides_sample.csv\\\"\\n\\nNEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\\n\\nDATABASE_URL = \\\"sqlite:///project.db\\\"\\nDATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\nQUERY_DIRECTORY = \\\"queries\\\"\";\n",
       "                var nbb_formatted_code = \"# any constants you might need, for example:\\n\\nTAXI_URL = \\\"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\\\"\\n# add other constants to refer to any local data, e.g. uber & weather\\nUBER_CSV = \\\"uber_rides_sample.csv\\\"\\n\\nNEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\\n\\nDATABASE_URL = \\\"sqlite:///project.db\\\"\\nDATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\nQUERY_DIRECTORY = \\\"queries\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what youâ€™re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26fe17",
   "metadata": {},
   "source": [
    "    \"\"\"Summary line.\n",
    "\n",
    "    Extended description of function.\n",
    "\n",
    "    Args:\n",
    "        arg1 (int): Description of arg1\n",
    "        arg2 (str): Description of arg2\n",
    "\n",
    "    Returns:\n",
    "        bool: Description of return value\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "# def calculate_distance(from_coord, to_coord):\n",
    "#     \"\"\"Caculate the distance between two coordinates\n",
    "\n",
    "#     Args:\n",
    "#         from_coord (tuple): A pair values (float) of latitude and longitude\n",
    "#         to_coord (tuple): A pair values (float) of latitude and longitude\n",
    "\n",
    "#     Returns:\n",
    "#         float: the distance, round to 3 decimals\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # convert degrees to radians\n",
    "#     lat1, lon1 = radians(from_coord[0]), radians(from_coord[1])\n",
    "#     lat2, lon2 = radians(to_coord[0]), radians(to_coord[1])\n",
    "\n",
    "#     # apply Haversine formula\n",
    "#     dlat = lat2 - lat1\n",
    "#     dlon = lon2 - lon1\n",
    "\n",
    "#     r = 6373.0  # radius of earth (km)\n",
    "\n",
    "#     a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "#     c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "#     distance = round(r * c, 3)\n",
    "\n",
    "#     return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473325dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def calculate_distance(row):\\n    \\\"\\\"\\\"Caculate the distance between two coordinates\\n\\n    Args:\\n        from_coord (tuple): A pair values (float) of latitude and longitude\\n        to_coord (tuple): A pair values (float) of latitude and longitude\\n\\n    Returns:\\n        float: the distance, round to 3 decimals\\n\\n    \\\"\\\"\\\"\\n\\n    # convert degrees to radians\\n    lat1, lon1 = radians(row[\\\"pickup_latitude\\\"]), radians(row[\\\"pickup_longitude\\\"])\\n    lat2, lon2 = radians(row[\\\"dropoff_latitude\\\"]), radians(row[\\\"dropoff_longitude\\\"])\\n\\n    # apply Haversine formula\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n\\n    r = 6373.0  # radius of earth (km)\\n\\n    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\\n\\n    distance = round(r * c, 3)\\n\\n    return distance\";\n",
       "                var nbb_formatted_code = \"def calculate_distance(row):\\n    \\\"\\\"\\\"Caculate the distance between two coordinates\\n\\n    Args:\\n        from_coord (tuple): A pair values (float) of latitude and longitude\\n        to_coord (tuple): A pair values (float) of latitude and longitude\\n\\n    Returns:\\n        float: the distance, round to 3 decimals\\n\\n    \\\"\\\"\\\"\\n\\n    # convert degrees to radians\\n    lat1, lon1 = radians(row[\\\"pickup_latitude\\\"]), radians(row[\\\"pickup_longitude\\\"])\\n    lat2, lon2 = radians(row[\\\"dropoff_latitude\\\"]), radians(row[\\\"dropoff_longitude\\\"])\\n\\n    # apply Haversine formula\\n    dlat = lat2 - lat1\\n    dlon = lon2 - lon1\\n\\n    r = 6373.0  # radius of earth (km)\\n\\n    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\\n\\n    distance = round(r * c, 3)\\n\\n    return distance\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_distance(row):\n",
    "    \"\"\"Caculate the distance between two coordinates\n",
    "\n",
    "    Args:\n",
    "        from_coord (tuple): A pair values (float) of latitude and longitude\n",
    "        to_coord (tuple): A pair values (float) of latitude and longitude\n",
    "\n",
    "    Returns:\n",
    "        float: the distance, round to 3 decimals\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert degrees to radians\n",
    "    lat1, lon1 = radians(row[\"pickup_latitude\"]), radians(row[\"pickup_longitude\"])\n",
    "    lat2, lon2 = radians(row[\"dropoff_latitude\"]), radians(row[\"dropoff_longitude\"])\n",
    "\n",
    "    # apply Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    r = 6373.0  # radius of earth (km)\n",
    "\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = round(r * c, 3)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6e6a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# calculate_distance(foo.iloc[0])\\n# foo.iloc[0]\";\n",
       "                var nbb_formatted_code = \"# calculate_distance(foo.iloc[0])\\n# foo.iloc[0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate_distance(foo.iloc[0])\n",
    "# foo.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def add_distance_column(dataframe):\\n    dataframe[\\\"distance\\\"] = dataframe.apply(calculate_distance, axis=1)\\n\\n    return dataframe\";\n",
       "                var nbb_formatted_code = \"def add_distance_column(dataframe):\\n    dataframe[\\\"distance\\\"] = dataframe.apply(calculate_distance, axis=1)\\n\\n    return dataframe\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    dataframe[\"distance\"] = dataframe.apply(calculate_distance, axis=1)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo1 = add_distance_column(foo)\n",
    "# foo1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def find_taxi_parquet_urls():\\n    \\\"\\\"\\\"Retrieve the yellow taxi parquet urls.\\n\\n    The function retrieves the url from January 2009 through June 2015.\\n\\n    Args:\\n        None\\n\\n    Returns:\\n        list: Desired urls as list of strings\\n\\n    \\\"\\\"\\\"\\n    # Use requests library to get TAXI_URL html\\n    response = requests.get(TAXI_URL)\\n    html = response.content\\n\\n    # Use BeautifulSoup to get all yellow taxi parquet urls\\n    soup = bs4.BeautifulSoup(html, \\\"html.parser\\\")\\n    yellow_a_tags = soup.find_all(\\\"a\\\", attrs={\\\"title\\\": \\\"Yellow Taxi Trip Records\\\"})\\n    yellow_taxi_urls = [a[\\\"href\\\"] for a in yellow_a_tags]\\n\\n    # Use re moduel to filter the urls\\n    pattern = re.compile(\\n        r\\\"yellow_tripdata_20(09-(?:0\\\\d|1[0-2])|1[0-4]-(?:0\\\\d|1[0-2])|15-0[1-6]).parquet\\\"\\n    )\\n\\n    yellow_taxi_urls_desired = []\\n\\n    for link in yellow_taxi_urls:\\n        match = pattern.search(link)\\n        if match:\\n            yellow_taxi_urls_desired.append(match.string)\\n\\n    return yellow_taxi_urls_desired\";\n",
       "                var nbb_formatted_code = \"def find_taxi_parquet_urls():\\n    \\\"\\\"\\\"Retrieve the yellow taxi parquet urls.\\n\\n    The function retrieves the url from January 2009 through June 2015.\\n\\n    Args:\\n        None\\n\\n    Returns:\\n        list: Desired urls as list of strings\\n\\n    \\\"\\\"\\\"\\n    # Use requests library to get TAXI_URL html\\n    response = requests.get(TAXI_URL)\\n    html = response.content\\n\\n    # Use BeautifulSoup to get all yellow taxi parquet urls\\n    soup = bs4.BeautifulSoup(html, \\\"html.parser\\\")\\n    yellow_a_tags = soup.find_all(\\\"a\\\", attrs={\\\"title\\\": \\\"Yellow Taxi Trip Records\\\"})\\n    yellow_taxi_urls = [a[\\\"href\\\"] for a in yellow_a_tags]\\n\\n    # Use re moduel to filter the urls\\n    pattern = re.compile(\\n        r\\\"yellow_tripdata_20(09-(?:0\\\\d|1[0-2])|1[0-4]-(?:0\\\\d|1[0-2])|15-0[1-6]).parquet\\\"\\n    )\\n\\n    yellow_taxi_urls_desired = []\\n\\n    for link in yellow_taxi_urls:\\n        match = pattern.search(link)\\n        if match:\\n            yellow_taxi_urls_desired.append(match.string)\\n\\n    return yellow_taxi_urls_desired\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_taxi_parquet_urls():\n",
    "    \"\"\"Retrieve the yellow taxi parquet urls.\n",
    "\n",
    "    The function retrieves the url from January 2009 through June 2015.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        list: Desired urls as list of strings\n",
    "\n",
    "    \"\"\"\n",
    "    # Use requests library to get TAXI_URL html\n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "\n",
    "    # Use BeautifulSoup to get all yellow taxi parquet urls\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    yellow_taxi_urls = [a[\"href\"] for a in yellow_a_tags]\n",
    "\n",
    "    # Use re moduel to filter the urls\n",
    "    pattern = re.compile(\n",
    "        r\"yellow_tripdata_20(09-(?:0\\d|1[0-2])|1[0-4]-(?:0\\d|1[0-2])|15-0[1-6]).parquet\"\n",
    "    )\n",
    "\n",
    "    yellow_taxi_urls_desired = []\n",
    "\n",
    "    for link in yellow_taxi_urls:\n",
    "        match = pattern.search(link)\n",
    "        if match:\n",
    "            yellow_taxi_urls_desired.append(match.string)\n",
    "\n",
    "    return yellow_taxi_urls_desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = find_taxi_parquet_urls()\n",
    "# len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb298bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated\n",
    "# def download_taxi_data(taxi_parquet_url):\n",
    "#     for url in taxi_parquet_url:\n",
    "\n",
    "#         response = requests.get(url, stream=True)\n",
    "#         file_name = url.split(\"/\")[-1]\n",
    "#         # file_path = os.getcwd() + '/datasets/yellow_taxi_data/'\n",
    "\n",
    "#         with open(file_name, \"wb\") as f:\n",
    "#             for chunk in response.iter_content(chunk_size=1024):\n",
    "#                 if chunk:\n",
    "#                     f.write(chunk)\n",
    "# Download the taxi parquet files to the current folder\n",
    "\n",
    "# taxi_parquet_url = find_taxi_parquet_urls()\n",
    "# download_taxi_data(taxi_parquet_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed1 = [\n",
    "    \"Trip_Pickup_DateTime\",\n",
    "    \"Trip_Dropoff_DateTime\",\n",
    "    \"Start_Lon\",\n",
    "    \"Start_Lat\",\n",
    "    \"End_Lon\",\n",
    "    \"End_Lat\",\n",
    "    \"Tip_Amt\",\n",
    "]  # 2009-02\n",
    "\n",
    "columns_needed2 = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"tip_amount\",\n",
    "]  # 2014-02\n",
    "\n",
    "columns_needed3 = [\n",
    "    \"pickup_datetime\",\n",
    "    \"dropoff_datetime\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"tip_amount\",\n",
    "]  # 2010-01\n",
    "\n",
    "df = pd.read_parquet(\"yellow_tripdata_2015-01.parquet\")\n",
    "\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb06a7",
   "metadata": {},
   "source": [
    "### Load taxi zones shp file and convert the polygon to coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443e0be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def convert_geometry(polygon):\\n    \\\"\\\"\\\"Conver polygon to its center point\\n\\n    Args:\\n        polygon (Polygon): shapely.geometry.polygon.Polygon type\\n\\n    Returns:\\n        tuple: Contain the latitude and longitude values\\n\\n    \\\"\\\"\\\"\\n    lon = polygon.centroid.x\\n    lat = polygon.centroid.y\\n    return (lat, lon)\\n\\n\\ngdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# gdf[\\\"center_lon\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.x)\\n# gdf[\\\"center_lat\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.y)\\ngdf[\\\"location_coordinate\\\"] = gdf[\\\"geometry\\\"].apply(convert_geometry)\\n\\n# Only keep the ID and coordinate columns\\ngdf = gdf[[\\\"LocationID\\\", \\\"location_coordinate\\\"]]\\n\\n# Remove duplicate LocationID: 56 and 103\\ngdf = gdf[~gdf[\\\"LocationID\\\"].duplicated(keep=False)]\";\n",
       "                var nbb_formatted_code = \"def convert_geometry(polygon):\\n    \\\"\\\"\\\"Conver polygon to its center point\\n\\n    Args:\\n        polygon (Polygon): shapely.geometry.polygon.Polygon type\\n\\n    Returns:\\n        tuple: Contain the latitude and longitude values\\n\\n    \\\"\\\"\\\"\\n    lon = polygon.centroid.x\\n    lat = polygon.centroid.y\\n    return (lat, lon)\\n\\n\\ngdf = geopandas.read_file(\\\"taxi_zones/taxi_zones.shp\\\").to_crs(4326)\\n# gdf[\\\"center_lon\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.x)\\n# gdf[\\\"center_lat\\\"] = gdf[\\\"geometry\\\"].apply(lambda p: p.centroid.y)\\ngdf[\\\"location_coordinate\\\"] = gdf[\\\"geometry\\\"].apply(convert_geometry)\\n\\n# Only keep the ID and coordinate columns\\ngdf = gdf[[\\\"LocationID\\\", \\\"location_coordinate\\\"]]\\n\\n# Remove duplicate LocationID: 56 and 103\\ngdf = gdf[~gdf[\\\"LocationID\\\"].duplicated(keep=False)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_geometry(polygon):\n",
    "    \"\"\"Conver polygon to its center point\n",
    "\n",
    "    Args:\n",
    "        polygon (Polygon): shapely.geometry.polygon.Polygon type\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contain the latitude and longitude values\n",
    "\n",
    "    \"\"\"\n",
    "    lon = polygon.centroid.x\n",
    "    lat = polygon.centroid.y\n",
    "    return (lat, lon)\n",
    "\n",
    "\n",
    "gdf = geopandas.read_file(\"taxi_zones/taxi_zones.shp\").to_crs(4326)\n",
    "# gdf[\"center_lon\"] = gdf[\"geometry\"].apply(lambda p: p.centroid.x)\n",
    "# gdf[\"center_lat\"] = gdf[\"geometry\"].apply(lambda p: p.centroid.y)\n",
    "gdf[\"location_coordinate\"] = gdf[\"geometry\"].apply(convert_geometry)\n",
    "\n",
    "# Only keep the ID and coordinate columns\n",
    "gdf = gdf[[\"LocationID\", \"location_coordinate\"]]\n",
    "\n",
    "# Remove duplicate LocationID: 56 and 103\n",
    "gdf = gdf[~gdf[\"LocationID\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33dcfddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def clean_taxi_data_with_locationId(df):\\n    # Keep only the columns that matters\\n    df = df[\\n        [\\n            \\\"tpep_pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\",\\n            \\\"PULocationID\\\",\\n            \\\"DOLocationID\\\",\\n            \\\"tip_amount\\\",\\n        ]\\n    ]\\n    # Drop rows where pickup location ID is the same as drop-off\\n    df = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\n\\n    # TODO: test dropoff Location ID == 56 & 103 (both ID have mutilple geometry entries)\\n    #     df = df.drop(\\n    #         df[\\n    #             (df.PULocationID == 56)\\n    #             | (df.PULocationID == 103)\\n    #             | (df.DOLocationID == 56)\\n    #             | (df.DOLocationID == 103)\\n    #         ].index\\n    #     )\\n\\n    # Convert LocationID to coordinate\\n    df[\\\"pickup_location\\\"] = df[\\\"PULocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    df[\\\"dropoff_location\\\"] = df[\\\"DOLocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    # Split the coordinate into latitude and longitude\\n    df[[\\\"pickup_latitude\\\", \\\"pickup_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"pickup_location\\\"].tolist(), index=df.index\\n    )\\n    df[[\\\"dropoff_latitude\\\", \\\"dropoff_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"dropoff_location\\\"].tolist(), index=df.index\\n    )\\n\\n    # Drop LocationID columns\\n    df = df.drop(\\n        columns=[\\\"PULocationID\\\", \\\"DOLocationID\\\", \\\"pickup_location\\\", \\\"dropoff_location\\\"]\\n    ).reset_index(drop=True)\\n\\n    # Normalize column names\\n    df = df.rename(\\n        columns={\\n            \\\"tpep_pickup_datetime\\\": \\\"pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\": \\\"dropoff_datetime\\\",\\n        }\\n    )\\n\\n    return df\";\n",
       "                var nbb_formatted_code = \"def clean_taxi_data_with_locationId(df):\\n    # Keep only the columns that matters\\n    df = df[\\n        [\\n            \\\"tpep_pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\",\\n            \\\"PULocationID\\\",\\n            \\\"DOLocationID\\\",\\n            \\\"tip_amount\\\",\\n        ]\\n    ]\\n    # Drop rows where pickup location ID is the same as drop-off\\n    df = df[df[\\\"PULocationID\\\"] != df[\\\"DOLocationID\\\"]]\\n\\n    # TODO: test dropoff Location ID == 56 & 103 (both ID have mutilple geometry entries)\\n    #     df = df.drop(\\n    #         df[\\n    #             (df.PULocationID == 56)\\n    #             | (df.PULocationID == 103)\\n    #             | (df.DOLocationID == 56)\\n    #             | (df.DOLocationID == 103)\\n    #         ].index\\n    #     )\\n\\n    # Convert LocationID to coordinate\\n    df[\\\"pickup_location\\\"] = df[\\\"PULocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    df[\\\"dropoff_location\\\"] = df[\\\"DOLocationID\\\"].map(\\n        gdf.set_index(\\\"LocationID\\\")[\\\"location_coordinate\\\"]\\n    )\\n    # Split the coordinate into latitude and longitude\\n    df[[\\\"pickup_latitude\\\", \\\"pickup_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"pickup_location\\\"].tolist(), index=df.index\\n    )\\n    df[[\\\"dropoff_latitude\\\", \\\"dropoff_longitude\\\"]] = pd.DataFrame(\\n        df[\\\"dropoff_location\\\"].tolist(), index=df.index\\n    )\\n\\n    # Drop LocationID columns\\n    df = df.drop(\\n        columns=[\\\"PULocationID\\\", \\\"DOLocationID\\\", \\\"pickup_location\\\", \\\"dropoff_location\\\"]\\n    ).reset_index(drop=True)\\n\\n    # Normalize column names\\n    df = df.rename(\\n        columns={\\n            \\\"tpep_pickup_datetime\\\": \\\"pickup_datetime\\\",\\n            \\\"tpep_dropoff_datetime\\\": \\\"dropoff_datetime\\\",\\n        }\\n    )\\n\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_taxi_data_with_locationId(df):\n",
    "    # Keep only the columns that matters\n",
    "    df = df[\n",
    "        [\n",
    "            \"tpep_pickup_datetime\",\n",
    "            \"tpep_dropoff_datetime\",\n",
    "            \"PULocationID\",\n",
    "            \"DOLocationID\",\n",
    "            \"tip_amount\",\n",
    "        ]\n",
    "    ]\n",
    "    # Drop rows where pickup location ID is the same as drop-off\n",
    "    df = df[df[\"PULocationID\"] != df[\"DOLocationID\"]]\n",
    "\n",
    "    # TODO: test dropoff Location ID == 56 & 103 (both ID have mutilple geometry entries)\n",
    "    #     df = df.drop(\n",
    "    #         df[\n",
    "    #             (df.PULocationID == 56)\n",
    "    #             | (df.PULocationID == 103)\n",
    "    #             | (df.DOLocationID == 56)\n",
    "    #             | (df.DOLocationID == 103)\n",
    "    #         ].index\n",
    "    #     )\n",
    "\n",
    "    # Convert LocationID to coordinate\n",
    "    df[\"pickup_location\"] = df[\"PULocationID\"].map(\n",
    "        gdf.set_index(\"LocationID\")[\"location_coordinate\"]\n",
    "    )\n",
    "    df[\"dropoff_location\"] = df[\"DOLocationID\"].map(\n",
    "        gdf.set_index(\"LocationID\")[\"location_coordinate\"]\n",
    "    )\n",
    "    # Split the coordinate into latitude and longitude\n",
    "    df[[\"pickup_latitude\", \"pickup_longitude\"]] = pd.DataFrame(\n",
    "        df[\"pickup_location\"].tolist(), index=df.index\n",
    "    )\n",
    "    df[[\"dropoff_latitude\", \"dropoff_longitude\"]] = pd.DataFrame(\n",
    "        df[\"dropoff_location\"].tolist(), index=df.index\n",
    "    )\n",
    "\n",
    "    # Drop LocationID columns\n",
    "    df = df.drop(\n",
    "        columns=[\"PULocationID\", \"DOLocationID\", \"pickup_location\", \"dropoff_location\"]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Normalize column names\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
    "            \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def get_and_clean_month_taxi_data(url):\\n    response = requests.get(url, stream=True)\\n    file_name = url.split(\\\"/\\\")[-1]\\n\\n    # Download file if it does not exist\\n    if not os.path.isfile(file_name):\\n        with open(file_name, \\\"wb\\\") as f:\\n            for chunk in response.iter_content(chunk_size=1024):\\n                if chunk:\\n                    f.write(chunk)\\n\\n    df = pd.read_parquet(file_name)\\n\\n    # There are three dataset types for taxi data\\n    # 1. Has location ID\\n    if \\\"PULocationID\\\" in df.columns:\\n        df = clean_taxi_data_with_locationId(df)\\n\\n    # 2. Column names with \\\"Start_Lon\\\", \\\"Start_Lat\\\", \\\"End_Lon\\\", \\\"End_Lat\\\"\\n    elif \\\"Start_Lon\\\" in df.columns:\\n        # Keep columns we need\\n        df = df[\\n            [\\n                \\\"Trip_Pickup_DateTime\\\",\\n                \\\"Trip_Dropoff_DateTime\\\",\\n                \\\"Start_Lon\\\",\\n                \\\"Start_Lat\\\",\\n                \\\"End_Lon\\\",\\n                \\\"End_Lat\\\",\\n                \\\"Tip_Amt\\\",\\n            ]\\n        ]\\n        # Normalize columns\\n        df = df.rename(\\n            columns={\\n                \\\"Trip_Pickup_DateTime\\\": \\\"pickup_datetime\\\",\\n                \\\"Trip_Dropoff_DateTime\\\": \\\"dropoff_datetime\\\",\\n                \\\"Start_Lon\\\": \\\"pickup_longitude\\\",\\n                \\\"Start_Lat\\\": \\\"pickup_latitude\\\",\\n                \\\"End_Lon\\\": \\\"dropoff_longitude\\\",\\n                \\\"End_Lat\\\": \\\"dropoff_latitude\\\",\\n                \\\"Tip_Amt\\\": \\\"tip_amount\\\",\\n            }\\n        )\\n\\n    # 3. Column names with \\\"pickup_datetime\\\" etc. which is our standard\\n    elif \\\"pickup_datetime\\\" in df.columns:\\n        # Keep columns we need\\n        df = df[\\n            [\\n                \\\"pickup_datetime\\\",\\n                \\\"dropoff_datetime\\\",\\n                \\\"pickup_longitude\\\",\\n                \\\"pickup_latitude\\\",\\n                \\\"dropoff_longitude\\\",\\n                \\\"dropoff_latitude\\\",\\n                \\\"tip_amount\\\",\\n            ]\\n        ]\\n\\n    else:\\n        raise (\\\"Dataset with unknown columns naming standard\\\")\\n\\n    # Drop out-off-region rows\\n    df = df.drop(\\n        df[\\n            (df.pickup_latitude > 40.908524)\\n            | (df.pickup_latitude < 40.560445)\\n            | (df.pickup_longitude > -73.717047)\\n            | (df.pickup_longitude < -74.242330)\\n            | (df.dropoff_latitude > 40.908524)\\n            | (df.dropoff_latitude < 40.560445)\\n            | (df.dropoff_longitude > -73.717047)\\n            | (df.dropoff_longitude < -74.242330)\\n        ].index\\n    )\\n\\n    # Convert pickup_datetime and dropoff_datetime to pandas DateTime\\n    df[\\\"pickup_datetime\\\"] = pd.to_datetime(df[\\\"pickup_datetime\\\"])\\n    df[\\\"dropoff_datetime\\\"] = pd.to_datetime(df[\\\"dropoff_datetime\\\"])\\n\\n    # Sampling:\\n    # sampling size = Uber data size / number of months of taxi datasets\\n    df = df.sample(n=int(195000 / 78))\\n\\n    return df.reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"def get_and_clean_month_taxi_data(url):\\n    response = requests.get(url, stream=True)\\n    file_name = url.split(\\\"/\\\")[-1]\\n\\n    # Download file if it does not exist\\n    if not os.path.isfile(file_name):\\n        with open(file_name, \\\"wb\\\") as f:\\n            for chunk in response.iter_content(chunk_size=1024):\\n                if chunk:\\n                    f.write(chunk)\\n\\n    df = pd.read_parquet(file_name)\\n\\n    # There are three dataset types for taxi data\\n    # 1. Has location ID\\n    if \\\"PULocationID\\\" in df.columns:\\n        df = clean_taxi_data_with_locationId(df)\\n\\n    # 2. Column names with \\\"Start_Lon\\\", \\\"Start_Lat\\\", \\\"End_Lon\\\", \\\"End_Lat\\\"\\n    elif \\\"Start_Lon\\\" in df.columns:\\n        # Keep columns we need\\n        df = df[\\n            [\\n                \\\"Trip_Pickup_DateTime\\\",\\n                \\\"Trip_Dropoff_DateTime\\\",\\n                \\\"Start_Lon\\\",\\n                \\\"Start_Lat\\\",\\n                \\\"End_Lon\\\",\\n                \\\"End_Lat\\\",\\n                \\\"Tip_Amt\\\",\\n            ]\\n        ]\\n        # Normalize columns\\n        df = df.rename(\\n            columns={\\n                \\\"Trip_Pickup_DateTime\\\": \\\"pickup_datetime\\\",\\n                \\\"Trip_Dropoff_DateTime\\\": \\\"dropoff_datetime\\\",\\n                \\\"Start_Lon\\\": \\\"pickup_longitude\\\",\\n                \\\"Start_Lat\\\": \\\"pickup_latitude\\\",\\n                \\\"End_Lon\\\": \\\"dropoff_longitude\\\",\\n                \\\"End_Lat\\\": \\\"dropoff_latitude\\\",\\n                \\\"Tip_Amt\\\": \\\"tip_amount\\\",\\n            }\\n        )\\n\\n    # 3. Column names with \\\"pickup_datetime\\\" etc. which is our standard\\n    elif \\\"pickup_datetime\\\" in df.columns:\\n        # Keep columns we need\\n        df = df[\\n            [\\n                \\\"pickup_datetime\\\",\\n                \\\"dropoff_datetime\\\",\\n                \\\"pickup_longitude\\\",\\n                \\\"pickup_latitude\\\",\\n                \\\"dropoff_longitude\\\",\\n                \\\"dropoff_latitude\\\",\\n                \\\"tip_amount\\\",\\n            ]\\n        ]\\n\\n    else:\\n        raise (\\\"Dataset with unknown columns naming standard\\\")\\n\\n    # Drop out-off-region rows\\n    df = df.drop(\\n        df[\\n            (df.pickup_latitude > 40.908524)\\n            | (df.pickup_latitude < 40.560445)\\n            | (df.pickup_longitude > -73.717047)\\n            | (df.pickup_longitude < -74.242330)\\n            | (df.dropoff_latitude > 40.908524)\\n            | (df.dropoff_latitude < 40.560445)\\n            | (df.dropoff_longitude > -73.717047)\\n            | (df.dropoff_longitude < -74.242330)\\n        ].index\\n    )\\n\\n    # Convert pickup_datetime and dropoff_datetime to pandas DateTime\\n    df[\\\"pickup_datetime\\\"] = pd.to_datetime(df[\\\"pickup_datetime\\\"])\\n    df[\\\"dropoff_datetime\\\"] = pd.to_datetime(df[\\\"dropoff_datetime\\\"])\\n\\n    # Sampling:\\n    # sampling size = Uber data size / number of months of taxi datasets\\n    df = df.sample(n=int(195000 / 78))\\n\\n    return df.reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    file_name = url.split(\"/\")[-1]\n",
    "\n",
    "    # Download file if it does not exist\n",
    "    if not os.path.isfile(file_name):\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "    df = pd.read_parquet(file_name)\n",
    "\n",
    "    # There are three dataset types for taxi data\n",
    "    # 1. Has location ID\n",
    "    if \"PULocationID\" in df.columns:\n",
    "        df = clean_taxi_data_with_locationId(df)\n",
    "\n",
    "    # 2. Column names with \"Start_Lon\", \"Start_Lat\", \"End_Lon\", \"End_Lat\"\n",
    "    elif \"Start_Lon\" in df.columns:\n",
    "        # Keep columns we need\n",
    "        df = df[\n",
    "            [\n",
    "                \"Trip_Pickup_DateTime\",\n",
    "                \"Trip_Dropoff_DateTime\",\n",
    "                \"Start_Lon\",\n",
    "                \"Start_Lat\",\n",
    "                \"End_Lon\",\n",
    "                \"End_Lat\",\n",
    "                \"Tip_Amt\",\n",
    "            ]\n",
    "        ]\n",
    "        # Normalize columns\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"Trip_Pickup_DateTime\": \"pickup_datetime\",\n",
    "                \"Trip_Dropoff_DateTime\": \"dropoff_datetime\",\n",
    "                \"Start_Lon\": \"pickup_longitude\",\n",
    "                \"Start_Lat\": \"pickup_latitude\",\n",
    "                \"End_Lon\": \"dropoff_longitude\",\n",
    "                \"End_Lat\": \"dropoff_latitude\",\n",
    "                \"Tip_Amt\": \"tip_amount\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 3. Column names with \"pickup_datetime\" etc. which is our standard\n",
    "    elif \"pickup_datetime\" in df.columns:\n",
    "        # Keep columns we need\n",
    "        df = df[\n",
    "            [\n",
    "                \"pickup_datetime\",\n",
    "                \"dropoff_datetime\",\n",
    "                \"pickup_longitude\",\n",
    "                \"pickup_latitude\",\n",
    "                \"dropoff_longitude\",\n",
    "                \"dropoff_latitude\",\n",
    "                \"tip_amount\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        raise (\"Dataset with unknown columns naming standard\")\n",
    "\n",
    "    # Drop out-off-region rows\n",
    "    df = df.drop(\n",
    "        df[\n",
    "            (df.pickup_latitude > 40.908524)\n",
    "            | (df.pickup_latitude < 40.560445)\n",
    "            | (df.pickup_longitude > -73.717047)\n",
    "            | (df.pickup_longitude < -74.242330)\n",
    "            | (df.dropoff_latitude > 40.908524)\n",
    "            | (df.dropoff_latitude < 40.560445)\n",
    "            | (df.dropoff_longitude > -73.717047)\n",
    "            | (df.dropoff_longitude < -74.242330)\n",
    "        ].index\n",
    "    )\n",
    "\n",
    "    # Convert pickup_datetime and dropoff_datetime to pandas DateTime\n",
    "    df[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"])\n",
    "    df[\"dropoff_datetime\"] = pd.to_datetime(df[\"dropoff_datetime\"])\n",
    "\n",
    "    # Sampling:\n",
    "    # sampling size = Uber data size / number of months of taxi datasets\n",
    "    df = df.sample(n=int(195000 / 78))\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.isfile(\"yellow_tripdata_2013-05.parquet\")\n",
    "# # foo = get_and_clean_month_taxi_data(\n",
    "# #     \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet\"\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed418242",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(200000 / 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def get_and_clean_taxi_data():\\n    all_taxi_dataframes = []\\n\\n    all_csv_urls = find_taxi_parquet_urls()\\n    for csv_url in all_csv_urls:\\n        # maybe: first try to see if you've downloaded this exact\\n        # file already and saved it before trying again\\n        dataframe = get_and_clean_month_taxi_data(csv_url)\\n        add_distance_column(dataframe)\\n        # maybe: if the file hasn't been saved, save it so you can\\n        # avoid re-downloading it if you re-run the function\\n\\n        all_taxi_dataframes.append(dataframe)\\n\\n    # create one gigantic dataframe with data from every month needed\\n    taxi_data = pd.concat(all_taxi_dataframes, ignore_index=True)\\n    return taxi_data\";\n",
       "                var nbb_formatted_code = \"def get_and_clean_taxi_data():\\n    all_taxi_dataframes = []\\n\\n    all_csv_urls = find_taxi_parquet_urls()\\n    for csv_url in all_csv_urls:\\n        # maybe: first try to see if you've downloaded this exact\\n        # file already and saved it before trying again\\n        dataframe = get_and_clean_month_taxi_data(csv_url)\\n        add_distance_column(dataframe)\\n        # maybe: if the file hasn't been saved, save it so you can\\n        # avoid re-downloading it if you re-run the function\\n\\n        all_taxi_dataframes.append(dataframe)\\n\\n    # create one gigantic dataframe with data from every month needed\\n    taxi_data = pd.concat(all_taxi_dataframes, ignore_index=True)\\n    return taxi_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "\n",
    "    all_csv_urls = find_taxi_parquet_urls()\n",
    "    for csv_url in all_csv_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        add_distance_column(dataframe)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "\n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "\n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes, ignore_index=True)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def load_and_clean_uber_data(csv_file):\\n    # Load and filter the columns\\n    df = pd.read_csv(\\n        csv_file,\\n        usecols=[\\n            \\\"pickup_datetime\\\",\\n            \\\"pickup_longitude\\\",\\n            \\\"pickup_latitude\\\",\\n            \\\"dropoff_longitude\\\",\\n            \\\"dropoff_latitude\\\",\\n        ],\\n    )\\n\\n    # Drop out-off-region rows\\n    df = df.drop(\\n        df[\\n            (df.pickup_latitude > 40.908524)\\n            | (df.pickup_latitude < 40.560445)\\n            | (df.pickup_longitude > -73.717047)\\n            | (df.pickup_longitude < -74.242330)\\n            | (df.dropoff_latitude > 40.908524)\\n            | (df.dropoff_latitude < 40.560445)\\n            | (df.dropoff_longitude > -73.717047)\\n            | (df.dropoff_longitude < -74.242330)\\n        ].index\\n    )\\n\\n    # Convert pickup_datetime column to pandas DateTime\\n    df[\\\"pickup_datetime\\\"] = pd.to_datetime(df[\\\"pickup_datetime\\\"])\\n    # Convert UTC to EST\\n    df[\\\"pickup_datetime\\\"] = df[\\\"pickup_datetime\\\"].dt.tz_convert(\\\"US/Eastern\\\")\\n    # Drop timezone suffix\\n    df[\\\"pickup_datetime\\\"] = df[\\\"pickup_datetime\\\"].dt.tz_localize(None)\\n\\n    return df\";\n",
       "                var nbb_formatted_code = \"def load_and_clean_uber_data(csv_file):\\n    # Load and filter the columns\\n    df = pd.read_csv(\\n        csv_file,\\n        usecols=[\\n            \\\"pickup_datetime\\\",\\n            \\\"pickup_longitude\\\",\\n            \\\"pickup_latitude\\\",\\n            \\\"dropoff_longitude\\\",\\n            \\\"dropoff_latitude\\\",\\n        ],\\n    )\\n\\n    # Drop out-off-region rows\\n    df = df.drop(\\n        df[\\n            (df.pickup_latitude > 40.908524)\\n            | (df.pickup_latitude < 40.560445)\\n            | (df.pickup_longitude > -73.717047)\\n            | (df.pickup_longitude < -74.242330)\\n            | (df.dropoff_latitude > 40.908524)\\n            | (df.dropoff_latitude < 40.560445)\\n            | (df.dropoff_longitude > -73.717047)\\n            | (df.dropoff_longitude < -74.242330)\\n        ].index\\n    )\\n\\n    # Convert pickup_datetime column to pandas DateTime\\n    df[\\\"pickup_datetime\\\"] = pd.to_datetime(df[\\\"pickup_datetime\\\"])\\n    # Convert UTC to EST\\n    df[\\\"pickup_datetime\\\"] = df[\\\"pickup_datetime\\\"].dt.tz_convert(\\\"US/Eastern\\\")\\n    # Drop timezone suffix\\n    df[\\\"pickup_datetime\\\"] = df[\\\"pickup_datetime\\\"].dt.tz_localize(None)\\n\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    # Load and filter the columns\n",
    "    df = pd.read_csv(\n",
    "        csv_file,\n",
    "        usecols=[\n",
    "            \"pickup_datetime\",\n",
    "            \"pickup_longitude\",\n",
    "            \"pickup_latitude\",\n",
    "            \"dropoff_longitude\",\n",
    "            \"dropoff_latitude\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Drop out-off-region rows\n",
    "    df = df.drop(\n",
    "        df[\n",
    "            (df.pickup_latitude > 40.908524)\n",
    "            | (df.pickup_latitude < 40.560445)\n",
    "            | (df.pickup_longitude > -73.717047)\n",
    "            | (df.pickup_longitude < -74.242330)\n",
    "            | (df.dropoff_latitude > 40.908524)\n",
    "            | (df.dropoff_latitude < 40.560445)\n",
    "            | (df.dropoff_longitude > -73.717047)\n",
    "            | (df.dropoff_longitude < -74.242330)\n",
    "        ].index\n",
    "    )\n",
    "\n",
    "    # Convert pickup_datetime column to pandas DateTime\n",
    "    df[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"])\n",
    "    # Convert UTC to EST\n",
    "    df[\"pickup_datetime\"] = df[\"pickup_datetime\"].dt.tz_convert(\"US/Eastern\")\n",
    "    # Drop timezone suffix\n",
    "    df[\"pickup_datetime\"] = df[\"pickup_datetime\"].dt.tz_localize(None)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325104f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "foo = load_and_clean_uber_data(UBER_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foo\n",
    "# # Convert pickup_datetime to pandas DateTime\n",
    "# df[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"])\n",
    "# # Convert UTC to EST\n",
    "# df[\"pickup_datetime\"] = df[\"pickup_datetime\"].dt.tz_convert(\"US/Eastern\")\n",
    "# # Drop timezone suffix\n",
    "# df[\"pickup_datetime\"] = df[\"pickup_datetime\"].dt.tz_localize(None)\n",
    "# # foo[\"pickup_datetime\"].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99323c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f836f118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def get_uber_data():\\n    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\\n    add_distance_column(uber_dataframe)\\n    return uber_dataframe\";\n",
       "                var nbb_formatted_code = \"def get_uber_data():\\n    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\\n    add_distance_column(uber_dataframe)\\n    return uber_dataframe\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1f50ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1eedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "# columns_needed_daily = [\"DATE\", \"DailyAverageWindSpeed\", \"REPORT_TYPE\"]\n",
    "\n",
    "# columns_needed_hourly = [\"DATE\", \"HourlyPrecipitation\", \"HourlyWindSpeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e979fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def clean_month_weather_data_hourly(csv_file):\\n    df = pd.read_csv(\\n        csv_file,\\n        usecols=[\\n            \\\"DATE\\\",\\n            \\\"HourlyPrecipitation\\\",\\n            \\\"HourlyWindSpeed\\\",\\n        ],\\n    )\\n    # Convert column to DataTime\\n    df[\\\"DATE\\\"] = pd.to_datetime(df[\\\"DATE\\\"])\\n    # Extract rows that has minute as 51\\n    df = df.loc[df[\\\"DATE\\\"].apply(lambda x: x.minute) == 51]\\n    # Replace NaN as 0 for HourlyPrecipitation\\n    # df[[\\\"HourlyPrecipitation\\\"]] = df[[\\\"HourlyPrecipitation\\\"]].fillna(0)\\n    return df\";\n",
       "                var nbb_formatted_code = \"def clean_month_weather_data_hourly(csv_file):\\n    df = pd.read_csv(\\n        csv_file,\\n        usecols=[\\n            \\\"DATE\\\",\\n            \\\"HourlyPrecipitation\\\",\\n            \\\"HourlyWindSpeed\\\",\\n        ],\\n    )\\n    # Convert column to DataTime\\n    df[\\\"DATE\\\"] = pd.to_datetime(df[\\\"DATE\\\"])\\n    # Extract rows that has minute as 51\\n    df = df.loc[df[\\\"DATE\\\"].apply(lambda x: x.minute) == 51]\\n    # Replace NaN as 0 for HourlyPrecipitation\\n    # df[[\\\"HourlyPrecipitation\\\"]] = df[[\\\"HourlyPrecipitation\\\"]].fillna(0)\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    df = pd.read_csv(\n",
    "        csv_file,\n",
    "        usecols=[\n",
    "            \"DATE\",\n",
    "            \"HourlyPrecipitation\",\n",
    "            \"HourlyWindSpeed\",\n",
    "        ],\n",
    "    )\n",
    "    # Convert column to DataTime\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    # Extract rows that has minute as 51\n",
    "    df = df.loc[df[\"DATE\"].apply(lambda x: x.minute) == 51]\n",
    "    # Replace NaN as 0 for HourlyPrecipitation\n",
    "    # df[[\"HourlyPrecipitation\"]] = df[[\"HourlyPrecipitation\"]].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# # hourly\n",
    "# df = pd.read_csv(\n",
    "#     \"2009_weather.csv\",\n",
    "#     usecols=[\n",
    "#         \"DATE\",\n",
    "#         \"REPORT_TYPE\",\n",
    "#         \"HourlyPrecipitation\",\n",
    "#         \"HourlyWindSpeed\",\n",
    "#         \"DailyAverageWindSpeed\",\n",
    "#     ],\n",
    "# )\n",
    "# # Conver column to DataTime\n",
    "# df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "# # Extract rows that has minute as 51\n",
    "# df = df.loc[df[\"DATE\"].apply(lambda x: x.minute) == 51]\n",
    "\n",
    "# df = clean_month_weather_data_hourly(\"2010_weather.csv\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0687581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"def clean_month_weather_data_daily(csv_file):\\n    df = pd.read_csv(\\n        csv_file,\\n        usecols=[\\n            \\\"DATE\\\",\\n            \\\"DailySustainedWindSpeed\\\",\\n            \\\"REPORT_TYPE\\\",\\n        ],\\n    )\\n    # Strip space in the REPORT_TYPE column\\n    df[\\\"REPORT_TYPE\\\"] = df[\\\"REPORT_TYPE\\\"].str.strip()\\n    # Extract rows that has REPORT_TYPE as SOD (Summary of Day Eeport)\\n    df = df.loc[df[\\\"REPORT_TYPE\\\"] == \\\"SOD\\\"]\\n    # Convert column to DataTime\\n    df[\\\"DATE\\\"] = pd.to_datetime(df[\\\"DATE\\\"])\\n    # Drop REPORT_TYPE column\\n    df = df.drop(columns=[\\\"REPORT_TYPE\\\"]).reset_index(drop=True)\\n    return df\";\n",
       "                var nbb_formatted_code = \"def clean_month_weather_data_daily(csv_file):\\n    df = pd.read_csv(\\n        csv_file,\\n        usecols=[\\n            \\\"DATE\\\",\\n            \\\"DailySustainedWindSpeed\\\",\\n            \\\"REPORT_TYPE\\\",\\n        ],\\n    )\\n    # Strip space in the REPORT_TYPE column\\n    df[\\\"REPORT_TYPE\\\"] = df[\\\"REPORT_TYPE\\\"].str.strip()\\n    # Extract rows that has REPORT_TYPE as SOD (Summary of Day Eeport)\\n    df = df.loc[df[\\\"REPORT_TYPE\\\"] == \\\"SOD\\\"]\\n    # Convert column to DataTime\\n    df[\\\"DATE\\\"] = pd.to_datetime(df[\\\"DATE\\\"])\\n    # Drop REPORT_TYPE column\\n    df = df.drop(columns=[\\\"REPORT_TYPE\\\"]).reset_index(drop=True)\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    df = pd.read_csv(\n",
    "        csv_file,\n",
    "        usecols=[\n",
    "            \"DATE\",\n",
    "            \"DailySustainedWindSpeed\",\n",
    "            \"REPORT_TYPE\",\n",
    "        ],\n",
    "    )\n",
    "    # Strip space in the REPORT_TYPE column\n",
    "    df[\"REPORT_TYPE\"] = df[\"REPORT_TYPE\"].str.strip()\n",
    "    # Extract rows that has REPORT_TYPE as SOD (Summary of Day Eeport)\n",
    "    df = df.loc[df[\"REPORT_TYPE\"] == \"SOD\"]\n",
    "    # Convert column to DataTime\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    # Drop REPORT_TYPE column\n",
    "    df = df.drop(columns=[\"REPORT_TYPE\"]).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cccf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "# # daily\n",
    "df = clean_month_weather_data_daily(\"2014_weather.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"def load_and_clean_weather_data():\\n    hourly_dataframes = []\\n    daily_dataframes = []\\n\\n    # add some way to find all weather CSV files\\n    # or just add the name/paths manually\\n    weather_csv_files = [\\n        \\\"2009_weather.csv\\\",\\n        \\\"2010_weather.csv\\\",\\n        \\\"2011_weather.csv\\\",\\n        \\\"2012_weather.csv\\\",\\n        \\\"2013_weather.csv\\\",\\n        \\\"2014_weather.csv\\\",\\n        \\\"2015_weather.csv\\\",\\n    ]\\n\\n    for csv_file in weather_csv_files:\\n        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\\n        daily_dataframe = clean_month_weather_data_daily(csv_file)\\n        hourly_dataframes.append(hourly_dataframe)\\n        daily_dataframes.append(daily_dataframe)\\n\\n    # create two dataframes with hourly & daily data from every month\\n    hourly_data = pd.concat(hourly_dataframes, ignore_index=True)\\n    daily_data = pd.concat(daily_dataframes, ignore_index=True)\\n\\n    return hourly_data, daily_data\";\n",
       "                var nbb_formatted_code = \"def load_and_clean_weather_data():\\n    hourly_dataframes = []\\n    daily_dataframes = []\\n\\n    # add some way to find all weather CSV files\\n    # or just add the name/paths manually\\n    weather_csv_files = [\\n        \\\"2009_weather.csv\\\",\\n        \\\"2010_weather.csv\\\",\\n        \\\"2011_weather.csv\\\",\\n        \\\"2012_weather.csv\\\",\\n        \\\"2013_weather.csv\\\",\\n        \\\"2014_weather.csv\\\",\\n        \\\"2015_weather.csv\\\",\\n    ]\\n\\n    for csv_file in weather_csv_files:\\n        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\\n        daily_dataframe = clean_month_weather_data_daily(csv_file)\\n        hourly_dataframes.append(hourly_dataframe)\\n        daily_dataframes.append(daily_dataframe)\\n\\n    # create two dataframes with hourly & daily data from every month\\n    hourly_data = pd.concat(hourly_dataframes, ignore_index=True)\\n    daily_data = pd.concat(daily_dataframes, ignore_index=True)\\n\\n    return hourly_data, daily_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "\n",
    "    # add some way to find all weather CSV files\n",
    "    # or just add the name/paths manually\n",
    "    weather_csv_files = [\n",
    "        \"2009_weather.csv\",\n",
    "        \"2010_weather.csv\",\n",
    "        \"2011_weather.csv\",\n",
    "        \"2012_weather.csv\",\n",
    "        \"2013_weather.csv\",\n",
    "        \"2014_weather.csv\",\n",
    "        \"2015_weather.csv\",\n",
    "    ]\n",
    "\n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "\n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes, ignore_index=True)\n",
    "    daily_data = pd.concat(daily_dataframes, ignore_index=True)\n",
    "\n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hourly_weather_data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"taxi_data = get_and_clean_taxi_data()\\nuber_data = get_uber_data()\\nhourly_weather_data, daily_weather_data = load_and_clean_weather_data()\";\n",
       "                var nbb_formatted_code = \"taxi_data = get_and_clean_taxi_data()\\nuber_data = get_uber_data()\\nhourly_weather_data, daily_weather_data = load_and_clean_weather_data()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 145;\n",
       "                var nbb_unformatted_code = \"# DATABASE_URL = \\\"sqlite:///project.db\\\"\\n# DATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\n\\n# Create connection\\nengine = db.create_engine(DATABASE_URL, echo=True)\\n# Logging - print out generated SQL\\nsqllogger = logging.getLogger(\\\"sqlalchemy.engine.Engine\\\")\\nformatter = logging.Formatter(\\\"[sqlalchemy] %(message)s\\\")\\nsqllogger.handlers[0].setFormatter(formatter)\";\n",
       "                var nbb_formatted_code = \"# DATABASE_URL = \\\"sqlite:///project.db\\\"\\n# DATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\n\\n# Create connection\\nengine = db.create_engine(DATABASE_URL, echo=True)\\n# Logging - print out generated SQL\\nsqllogger = logging.getLogger(\\\"sqlalchemy.engine.Engine\\\")\\nformatter = logging.Formatter(\\\"[sqlalchemy] %(message)s\\\")\\nsqllogger.handlers[0].setFormatter(formatter)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DATABASE_URL = \"sqlite:///project.db\"\n",
    "# DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# Create connection\n",
    "engine = db.create_engine(DATABASE_URL, echo=True)\n",
    "# Logging - print out generated SQL\n",
    "sqllogger = logging.getLogger(\"sqlalchemy.engine.Engine\")\n",
    "formatter = logging.Formatter(\"[sqlalchemy] %(message)s\")\n",
    "sqllogger.handlers[0].setFormatter(formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a29627",
   "metadata": {},
   "source": [
    "### Create Python Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a035d74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 146;\n",
       "                var nbb_unformatted_code = \"# Create \\\"base\\\" class\\nBase = declarative_base()\";\n",
       "                var nbb_formatted_code = \"# Create \\\"base\\\" class\\nBase = declarative_base()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create \"base\" class\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2945df6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 147;\n",
       "                var nbb_unformatted_code = \"# Define Classes\\n\\nclass TAXI_TRIP(Base):\\n    __tablename__ = \\\"taxi_trips\\\"\\n    \\n    taxi_id = Column(Integer, primary_key=True)\\n    pickup_datetime = Column(DateTime)\\n    dropoff_datetime = Column(DateTime)\\n    tip_amount = Column(Float)\\n    pickup_latitude = Column(Float)\\n    pickup_longitude = Column(Float)\\n    dropoff_latitude = Column(Float)\\n    dropoff_longitude = Column(Float)\\n    distance = Column(Float)\\n\\n\\nclass UBER_TRIP(Base):\\n    __tablename__ = \\\"uber_trips\\\"\\n    \\n    uber_id = Column(Integer, primary_key=True)\\n    pickup_datetime = Column(DateTime)\\n    pickup_longitude = Column(Float)\\n    pickup_latitude = Column(Float)\\n    dropoff_longitude = Column(Float)\\n    dropoff_latitude = Column(Float)\\n    distance = Column(Float)\\n    \\n\\nclass HOURLY_WEATHER(Base):\\n    __tablename__ = \\\"hourly_weather\\\"\\n    \\n    hourly_weather_id = Column(Integer, primary_key=True)\\n    DATE = Column(DateTime)\\n    HourlyPrecipitation = Column(Float)\\n    HourlyWindSpeed = Column(Float)\\n    \\n    \\nclass DAILY_WEATHER(Base):\\n    __tablename__ = \\\"daily_weather\\\"\\n    \\n    daily_weather_id = Column(Integer, primary_key=True)\\n    DATE = Column(DateTime)\\n    DailySustainedWindSpeed = Column(Float)\";\n",
       "                var nbb_formatted_code = \"# Define Classes\\n\\n\\nclass TAXI_TRIP(Base):\\n    __tablename__ = \\\"taxi_trips\\\"\\n\\n    taxi_id = Column(Integer, primary_key=True)\\n    pickup_datetime = Column(DateTime)\\n    dropoff_datetime = Column(DateTime)\\n    tip_amount = Column(Float)\\n    pickup_latitude = Column(Float)\\n    pickup_longitude = Column(Float)\\n    dropoff_latitude = Column(Float)\\n    dropoff_longitude = Column(Float)\\n    distance = Column(Float)\\n\\n\\nclass UBER_TRIP(Base):\\n    __tablename__ = \\\"uber_trips\\\"\\n\\n    uber_id = Column(Integer, primary_key=True)\\n    pickup_datetime = Column(DateTime)\\n    pickup_longitude = Column(Float)\\n    pickup_latitude = Column(Float)\\n    dropoff_longitude = Column(Float)\\n    dropoff_latitude = Column(Float)\\n    distance = Column(Float)\\n\\n\\nclass HOURLY_WEATHER(Base):\\n    __tablename__ = \\\"hourly_weather\\\"\\n\\n    hourly_weather_id = Column(Integer, primary_key=True)\\n    DATE = Column(DateTime)\\n    HourlyPrecipitation = Column(Float)\\n    HourlyWindSpeed = Column(Float)\\n\\n\\nclass DAILY_WEATHER(Base):\\n    __tablename__ = \\\"daily_weather\\\"\\n\\n    daily_weather_id = Column(Integer, primary_key=True)\\n    DATE = Column(DateTime)\\n    DailySustainedWindSpeed = Column(Float)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define Classes\n",
    "\n",
    "class TAXI_TRIP(Base):\n",
    "    __tablename__ = \"taxi_trips\"\n",
    "    \n",
    "    taxi_id = Column(Integer, primary_key=True)\n",
    "    pickup_datetime = Column(DateTime)\n",
    "    dropoff_datetime = Column(DateTime)\n",
    "    tip_amount = Column(Float)\n",
    "    pickup_latitude = Column(Float)\n",
    "    pickup_longitude = Column(Float)\n",
    "    dropoff_latitude = Column(Float)\n",
    "    dropoff_longitude = Column(Float)\n",
    "    distance = Column(Float)\n",
    "\n",
    "\n",
    "class UBER_TRIP(Base):\n",
    "    __tablename__ = \"uber_trips\"\n",
    "    \n",
    "    uber_id = Column(Integer, primary_key=True)\n",
    "    pickup_datetime = Column(DateTime)\n",
    "    pickup_longitude = Column(Float)\n",
    "    pickup_latitude = Column(Float)\n",
    "    dropoff_longitude = Column(Float)\n",
    "    dropoff_latitude = Column(Float)\n",
    "    distance = Column(Float)\n",
    "    \n",
    "\n",
    "class HOURLY_WEATHER(Base):\n",
    "    __tablename__ = \"hourly_weather\"\n",
    "    \n",
    "    hourly_weather_id = Column(Integer, primary_key=True)\n",
    "    DATE = Column(DateTime)\n",
    "    HourlyPrecipitation = Column(Float)\n",
    "    HourlyWindSpeed = Column(Float)\n",
    "    \n",
    "    \n",
    "class DAILY_WEATHER(Base):\n",
    "    __tablename__ = \"daily_weather\"\n",
    "    \n",
    "    daily_weather_id = Column(Integer, primary_key=True)\n",
    "    DATE = Column(DateTime)\n",
    "    DailySustainedWindSpeed = Column(Float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "66110520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] PRAGMA main.table_info(\"taxi_trips\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"taxi_trips\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA main.table_info(\"uber_trips\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"uber_trips\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA main.table_info(\"hourly_weather\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"hourly_weather\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA main.table_info(\"daily_weather\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] PRAGMA temp.table_info(\"daily_weather\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] \n",
      "CREATE TABLE taxi_trips (\n",
      "\ttaxi_id INTEGER NOT NULL, \n",
      "\tpickup_datetime DATETIME, \n",
      "\tdropoff_datetime DATETIME, \n",
      "\ttip_amount FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdistance FLOAT, \n",
      "\tPRIMARY KEY (taxi_id)\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00064s] ()\n",
      "[sqlalchemy] \n",
      "CREATE TABLE uber_trips (\n",
      "\tuber_id INTEGER NOT NULL, \n",
      "\tpickup_datetime DATETIME, \n",
      "\tpickup_longitude FLOAT, \n",
      "\tpickup_latitude FLOAT, \n",
      "\tdropoff_longitude FLOAT, \n",
      "\tdropoff_latitude FLOAT, \n",
      "\tdistance FLOAT, \n",
      "\tPRIMARY KEY (uber_id)\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00054s] ()\n",
      "[sqlalchemy] \n",
      "CREATE TABLE hourly_weather (\n",
      "\thourly_weather_id INTEGER NOT NULL, \n",
      "\t\"DATE\" DATETIME, \n",
      "\t\"HourlyPrecipitation\" FLOAT, \n",
      "\t\"HourlyWindSpeed\" FLOAT, \n",
      "\tPRIMARY KEY (hourly_weather_id)\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00052s] ()\n",
      "[sqlalchemy] \n",
      "CREATE TABLE daily_weather (\n",
      "\tdaily_weather_id INTEGER NOT NULL, \n",
      "\t\"DATE\" DATETIME, \n",
      "\t\"DailySustainedWindSpeed\" FLOAT, \n",
      "\tPRIMARY KEY (daily_weather_id)\n",
      ")\n",
      "\n",
      "\n",
      "[sqlalchemy] [no key 0.00087s] ()\n",
      "[sqlalchemy] COMMIT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 148;\n",
       "                var nbb_unformatted_code = \"# Create table in the database from Base class\\nBase.metadata.create_all(engine, checkfirst=True)\";\n",
       "                var nbb_formatted_code = \"# Create table in the database from Base class\\nBase.metadata.create_all(engine, checkfirst=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create table in the database from Base class\n",
    "Base.metadata.create_all(engine, checkfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# if using SQL (as opposed to SQLAlchemy), define the commands\\n# to create your 4 tables/dataframes\\n\\nHOURLY_WEATHER_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS hourly_weather \\n(\\n    hourly_weather_id INTEGER PRIMARY KEY, \\n    date TEXT, \\n    hourlyPrecipitation REAL, \\n    hourlyWindSpeed REAL\\n);\\n\\\"\\\"\\\"\\n\\nDAILY_WEATHER_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS daily_weather \\n(\\n    daily_weather_id INTEGER PRIMARY KEY, \\n    date TEXT, \\n    dailySustainedWindSpeed REAL\\n);\\n\\\"\\\"\\\"\\n\\nTAXI_TRIPS_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS taxi_trips \\n(\\n    taxi_id INTEGER INTEGER PRIMARY KEY, \\n    pickup_datetime TEXT, \\n    dropoff_datetime TEXT,\\n    tip_amount REAL,\\n    pickup_latitude REAL,\\n    pickup_longitude REAL,\\n    dropoff_latitude REAL,\\n    dropoff_longitude REAL,\\n    distance REAL, \\n    \\n);\\n\\\"\\\"\\\"\\n\\nUBER_TRIPS_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS uber_trips \\n(\\n    uber_id INTEGER INTEGER PRIMARY KEY, \\n    pickup_datetime TEXT, \\n    pickup_longitude REAL, \\n    pickup_latitude REAL, \\n    dropoff_longitude REAL, \\n    dropoff_latitude REAL, \\n    distance REAL\\n);\\n\\\"\\\"\\\"\";\n",
       "                var nbb_formatted_code = \"# if using SQL (as opposed to SQLAlchemy), define the commands\\n# to create your 4 tables/dataframes\\n\\nHOURLY_WEATHER_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS hourly_weather \\n(\\n    hourly_weather_id INTEGER PRIMARY KEY, \\n    date TEXT, \\n    hourlyPrecipitation REAL, \\n    hourlyWindSpeed REAL\\n);\\n\\\"\\\"\\\"\\n\\nDAILY_WEATHER_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS daily_weather \\n(\\n    daily_weather_id INTEGER PRIMARY KEY, \\n    date TEXT, \\n    dailySustainedWindSpeed REAL\\n);\\n\\\"\\\"\\\"\\n\\nTAXI_TRIPS_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS taxi_trips \\n(\\n    taxi_id INTEGER INTEGER PRIMARY KEY, \\n    pickup_datetime TEXT, \\n    dropoff_datetime TEXT,\\n    tip_amount REAL,\\n    pickup_latitude REAL,\\n    pickup_longitude REAL,\\n    dropoff_latitude REAL,\\n    dropoff_longitude REAL,\\n    distance REAL, \\n    \\n);\\n\\\"\\\"\\\"\\n\\nUBER_TRIPS_SCHEMA = \\\"\\\"\\\"\\nCREATE TABLE IF NOT EXISTS uber_trips \\n(\\n    uber_id INTEGER INTEGER PRIMARY KEY, \\n    pickup_datetime TEXT, \\n    pickup_longitude REAL, \\n    pickup_latitude REAL, \\n    dropoff_longitude REAL, \\n    dropoff_latitude REAL, \\n    distance REAL\\n);\\n\\\"\\\"\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands\n",
    "# to create your 4 tables/dataframes\n",
    "\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather \n",
    "(\n",
    "    hourly_weather_id INTEGER PRIMARY KEY, \n",
    "    date TEXT, \n",
    "    hourlyPrecipitation REAL, \n",
    "    hourlyWindSpeed REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather \n",
    "(\n",
    "    daily_weather_id INTEGER PRIMARY KEY, \n",
    "    date TEXT, \n",
    "    dailySustainedWindSpeed REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips \n",
    "(\n",
    "    taxi_id INTEGER INTEGER PRIMARY KEY, \n",
    "    pickup_datetime TEXT, \n",
    "    dropoff_datetime TEXT,\n",
    "    tip_amount REAL,\n",
    "    pickup_latitude REAL,\n",
    "    pickup_longitude REAL,\n",
    "    dropoff_latitude REAL,\n",
    "    dropoff_longitude REAL,\n",
    "    distance REAL, \n",
    "    \n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips \n",
    "(\n",
    "    uber_id INTEGER INTEGER PRIMARY KEY, \n",
    "    pickup_datetime TEXT, \n",
    "    pickup_longitude REAL, \n",
    "    pickup_latitude REAL, \n",
    "    dropoff_longitude REAL, \n",
    "    dropoff_latitude REAL, \n",
    "    distance REAL\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# DATABASE_URL = \\\"sqlite:///project.db\\\"\\n# DATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\n\\n# create that required schema.sql file\\nwith open(DATABASE_SCHEMA_FILE, \\\"w\\\") as f:\\n    f.write(HOURLY_WEATHER_SCHEMA)\\n    f.write(DAILY_WEATHER_SCHEMA)\\n    f.write(TAXI_TRIPS_SCHEMA)\\n    f.write(UBER_TRIPS_SCHEMA)\";\n",
       "                var nbb_formatted_code = \"# DATABASE_URL = \\\"sqlite:///project.db\\\"\\n# DATABASE_SCHEMA_FILE = \\\"schema.sql\\\"\\n\\n# create that required schema.sql file\\nwith open(DATABASE_SCHEMA_FILE, \\\"w\\\") as f:\\n    f.write(HOURLY_WEATHER_SCHEMA)\\n    f.write(DAILY_WEATHER_SCHEMA)\\n    f.write(TAXI_TRIPS_SCHEMA)\\n    f.write(UBER_TRIPS_SCHEMA)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DATABASE_URL = \"sqlite:///project.db\"\n",
    "# DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a294c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sqlite3 project.db < schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove\n",
    "# create the tables with the schema files\n",
    "# with engine.connect() as connection:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 149;\n",
       "                var nbb_unformatted_code = \"def write_dataframes_to_table(table_to_df_dict, table_to_pk_dict):\\n\\n    for sql_table, dataframe in table_to_df_dict.items():\\n        dataframe.to_sql(\\n            sql_table,\\n            con=engine,\\n            index_label=table_to_pk_dict[sql_table],\\n            if_exists=\\\"append\\\",\\n        )\";\n",
       "                var nbb_formatted_code = \"def write_dataframes_to_table(table_to_df_dict, table_to_pk_dict):\\n\\n    for sql_table, dataframe in table_to_df_dict.items():\\n        dataframe.to_sql(\\n            sql_table,\\n            con=engine,\\n            index_label=table_to_pk_dict[sql_table],\\n            if_exists=\\\"append\\\",\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict, table_to_pk_dict):\n",
    "\n",
    "    for sql_table, dataframe in table_to_df_dict.items():\n",
    "        dataframe.to_sql(\n",
    "            sql_table,\n",
    "            con=engine,\n",
    "            index_label=table_to_pk_dict[sql_table],\n",
    "            if_exists=\"append\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 150;\n",
       "                var nbb_unformatted_code = \"map_table_name_to_dataframe = {\\n    \\\"taxi_trips\\\": taxi_data,\\n    \\\"uber_trips\\\": uber_data,\\n    \\\"hourly_weather\\\": hourly_weather_data,\\n    \\\"daily_weather\\\": daily_weather_data,\\n}\\n\\nmap_table_name_to_primary_key = {\\n    \\\"taxi_trips\\\": \\\"taxi_id\\\",\\n    \\\"uber_trips\\\": \\\"uber_id\\\",\\n    \\\"hourly_weather\\\": \\\"hourly_weather_id\\\",\\n    \\\"daily_weather\\\": \\\"daily_weather_id\\\",\\n}\";\n",
       "                var nbb_formatted_code = \"map_table_name_to_dataframe = {\\n    \\\"taxi_trips\\\": taxi_data,\\n    \\\"uber_trips\\\": uber_data,\\n    \\\"hourly_weather\\\": hourly_weather_data,\\n    \\\"daily_weather\\\": daily_weather_data,\\n}\\n\\nmap_table_name_to_primary_key = {\\n    \\\"taxi_trips\\\": \\\"taxi_id\\\",\\n    \\\"uber_trips\\\": \\\"uber_id\\\",\\n    \\\"hourly_weather\\\": \\\"hourly_weather_id\\\",\\n    \\\"daily_weather\\\": \\\"daily_weather_id\\\",\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}\n",
    "\n",
    "map_table_name_to_primary_key = {\n",
    "    \"taxi_trips\": \"taxi_id\",\n",
    "    \"uber_trips\": \"uber_id\",\n",
    "    \"hourly_weather\": \"hourly_weather_id\",\n",
    "    \"daily_weather\": \"daily_weather_id\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "74004f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] PRAGMA main.table_info(\"taxi_trips\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO taxi_trips (taxi_id, pickup_datetime, dropoff_datetime, tip_amount, pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, distance) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "[sqlalchemy] [generated in 1.47514s] ((0, '2015-01-14 07:27:39.000000', '2015-01-14 07:37:57.000000', 0.0, 40.74043841456513, -73.97649451946062, 40.7654835136402, -73.95473860364447, 3.335), (1, '2015-01-17 21:25:17.000000', '2015-01-17 21:38:01.000000', 2.1, 40.734575491016365, -74.00287471671791, 40.72375160905862, -73.97696808881017, 2.494), (2, '2015-01-18 12:47:24.000000', '2015-01-18 12:55:08.000000', 0.0, 40.76442085610594, -73.97756845303152, 40.747745222847335, -73.97849137603437, 1.856), (3, '2015-01-23 20:20:51.000000', '2015-01-23 20:32:38.000000', 2.26, 40.71777226635047, -74.00787950315832, 40.7403368943808, -73.99045758944533, 2.908), (4, '2015-01-15 19:25:40.000000', '2015-01-15 19:39:08.000000', 0.0, 40.75802748031876, -73.97769770225797, 40.77593184026933, -73.94651019130441, 3.297), (5, '2015-01-13 20:01:33.000000', '2015-01-13 20:31:39.000000', 11.47, 40.646984156143034, -73.7865332653343, 40.7403368943808, -73.99045758944533, 20.09), (6, '2015-01-08 12:22:59.000000', '2015-01-08 12:43:37.000000', 0.0, 40.74849662287896, -73.9924372796678, 40.7238876112567, -74.00153735040311, 2.843), (7, '2015-01-31 23:58:19.000000', '2015-02-01 00:06:18.000000', 0.5, 40.76623719991871, -73.99513495385925, 40.74849662287896, -73.9924372796678, 1.986)  ... displaying 10 of 195000 total bound parameter sets ...  (194998, '2009-12-23 08:34:00.000000', '2009-12-23 08:40:00.000000', 1.0, 40.76489, -73.954755, 40.776165, -73.94999799999998, 1.317), (194999, '2009-12-29 15:18:57.000000', '2009-12-29 15:24:32.000000', 0.0, 40.728104, -73.987937, 40.737325, -73.981335, 1.167))\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] PRAGMA main.table_info(\"uber_trips\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO uber_trips (uber_id, pickup_datetime, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, distance) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
      "[sqlalchemy] [generated in 0.84598s] ((0, '2015-05-07 15:52:06.000000', -73.99981689453125, 40.73835372924805, -73.99951171875, 40.72321701049805, 1.684), (1, '2009-07-17 16:04:56.000000', -73.994355, 40.728225, -73.99471, 40.750325, 2.458), (2, '2009-08-24 17:45:00.000000', -74.005043, 40.74077, -73.962565, 40.772647, 5.038), (3, '2009-06-26 04:22:21.000000', -73.976124, 40.790844, -73.965316, 40.803349, 1.662), (4, '2014-08-28 13:47:00.000000', -73.925023, 40.744085, -73.97308199999999, 40.761247, 4.477), (5, '2011-02-11 21:27:09.000000', -73.96901899999999, 40.75591, -73.96901899999999, 40.75591, 0.0), (6, '2014-10-12 03:04:00.000000', -73.96144699999999, 40.693965000000006, -73.871195, 40.774297, 11.735), (8, '2012-02-17 04:32:00.000000', -73.975187, 40.745767, -74.00272, 40.743537, 2.333)  ... displaying 10 of 195473 total bound parameter sets ...  (199998, '2015-05-20 10:56:25.000000', -73.99712371826173, 40.7254524230957, -73.98321533203125, 40.69541549682617, 3.541), (199999, '2010-05-15 00:08:00.000000', -73.98439499999999, 40.720077, -73.985508, 40.768793, 5.419))\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] PRAGMA main.table_info(\"hourly_weather\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO hourly_weather (hourly_weather_id, \"DATE\", \"HourlyPrecipitation\", \"HourlyWindSpeed\") VALUES (?, ?, ?, ?)\n",
      "[sqlalchemy] [generated in 0.20067s] ((0, '2009-01-01 00:51:00.000000', None, 18.0), (1, '2009-01-01 01:51:00.000000', None, 18.0), (2, '2009-01-01 02:51:00.000000', None, 18.0), (3, '2009-01-01 03:51:00.000000', None, 8.0), (4, '2009-01-01 04:51:00.000000', None, 11.0), (5, '2009-01-01 05:51:00.000000', None, 18.0), (6, '2009-01-01 06:51:00.000000', None, 14.0), (7, '2009-01-01 07:51:00.000000', None, 8.0)  ... displaying 10 of 60311 total bound parameter sets ...  (60309, '2015-12-31 22:51:00.000000', '0.00', 7.0), (60310, '2015-12-31 23:51:00.000000', '0.00', 5.0))\n",
      "[sqlalchemy] COMMIT\n",
      "[sqlalchemy] PRAGMA main.table_info(\"daily_weather\")\n",
      "[sqlalchemy] [raw sql] ()\n",
      "[sqlalchemy] BEGIN (implicit)\n",
      "[sqlalchemy] INSERT INTO daily_weather (daily_weather_id, \"DATE\", \"DailySustainedWindSpeed\") VALUES (?, ?, ?)\n",
      "[sqlalchemy] [generated in 0.00627s] ((0, '2009-01-02 23:59:00.000000', None), (1, '2009-01-06 23:59:00.000000', None), (2, '2009-01-07 23:59:00.000000', None), (3, '2009-01-10 23:59:00.000000', None), (4, '2009-01-11 23:59:00.000000', None), (5, '2009-01-15 23:59:00.000000', None), (6, '2009-01-18 23:59:00.000000', None), (7, '2009-01-19 23:59:00.000000', None)  ... displaying 10 of 1826 total bound parameter sets ...  (1824, '2015-12-30 23:59:00.000000', 9.0), (1825, '2015-12-31 23:59:00.000000', 14.0))\n",
      "[sqlalchemy] COMMIT\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 151;\n",
       "                var nbb_unformatted_code = \"write_dataframes_to_table(map_table_name_to_dataframe, map_table_name_to_primary_key)\";\n",
       "                var nbb_formatted_code = \"write_dataframes_to_table(map_table_name_to_dataframe, map_table_name_to_primary_key)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe, map_table_name_to_primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"def write_query_to_file(query, outfile):\\n    with open(outfile, \\\"w\\\") as f:\\n        f.write(query)\";\n",
       "                var nbb_formatted_code = \"def write_query_to_file(query, outfile):\\n    with open(outfile, \\\"w\\\") as f:\\n        f.write(query)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "\n",
    "Query the number of taxi trip for each hour from 01-2009 to 06-2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"QUERY_1 = \\\"\\\"\\\"\\nSELECT COUNT(taxi_id),strftime ('%H',pickup_datetime) AS hour\\nFROM taxi_trips\\nGROUP BY strftime ('%H',pickup_datetime)\\n\\\"\\\"\\\"\";\n",
       "                var nbb_formatted_code = \"QUERY_1 = \\\"\\\"\\\"\\nSELECT COUNT(taxi_id),strftime ('%H',pickup_datetime) AS hour\\nFROM taxi_trips\\nGROUP BY strftime ('%H',pickup_datetime)\\n\\\"\\\"\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUERY_1 = \"\"\"\n",
    "SELECT COUNT(taxi_id),strftime ('%H',pickup_datetime) AS hour\n",
    "FROM taxi_trips\n",
    "GROUP BY strftime ('%H',pickup_datetime)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26694b",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "From the output above, the most popular hour to take a Yellow Taxi is 19h, i.e. 7pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"write_query_to_file(QUERY_1, \\\"q1_hourly_taxi_trips.sql\\\")\";\n",
       "                var nbb_formatted_code = \"write_query_to_file(QUERY_1, \\\"q1_hourly_taxi_trips.sql\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_query_to_file(QUERY_1, \"q1_hourly_taxi_trips.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bcb035",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "\n",
    "Query the number of uber trips for each day of the week from 01-2009 to 06-2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af857bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2 = \"\"\"\n",
    "SELECT COUNT(uber_id),strftime ('%w',pickup_datetime) AS day\n",
    "FROM uber_trips\n",
    "GROUP BY strftime ('%w',pickup_datetime)\n",
    "\"\"\"\n",
    "engine.execute(QUERY_2).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda8ac8",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "From the output above, the most popular day of the week to take an Uber is Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0249e64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"write_query_to_file(QUERY_2, \\\"q2_day_of_week_uber_trips.sql\\\")\";\n",
       "                var nbb_formatted_code = \"write_query_to_file(QUERY_2, \\\"q2_day_of_week_uber_trips.sql\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_query_to_file(QUERY_2, \"q2_day_of_week_uber_trips.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41107ff",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "\n",
    "95% percentile of distance traveled for all hired trips during July 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3 = \"\"\"\n",
    "\n",
    "SELECT\n",
    "  distance AS '95% percentile of distance'\n",
    "FROM taxi_trips\n",
    "WHERE strftime('%m',pickup_datetime) = '07' AND strftime('%Y',pickup_datetime) = '2013'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "  distance AS '95% percentile of distance'\n",
    "FROM uber_trips\n",
    "WHERE strftime('%m',pickup_datetime) = '07' AND strftime('%Y',pickup_datetime) = '2013'\n",
    "\n",
    "ORDER BY distance ASC\n",
    "\n",
    "LIMIT 1\n",
    "OFFSET ROUND(\n",
    "    (\n",
    "    SELECT COUNT(distance) \n",
    "\n",
    "    FROM (\n",
    "        SELECT\n",
    "          distance\n",
    "        FROM taxi_trips\n",
    "        WHERE strftime('%m',pickup_datetime) = '07' AND strftime('%Y',pickup_datetime) = '2013'\n",
    "\n",
    "        UNION ALL\n",
    "\n",
    "        SELECT\n",
    "          distance\n",
    "        FROM uber_trips\n",
    "        WHERE strftime('%m',pickup_datetime) = '07' AND strftime('%Y',pickup_datetime) = '2013'\n",
    "        ) \n",
    "    ) * 9.5 / 10 - 1);\n",
    "\"\"\"\n",
    "engine.execute(QUERY_3).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1403c82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"write_query_to_file(QUERY_3, \\\"q3_95_percentile_travel_distance.sql\\\")\";\n",
       "                var nbb_formatted_code = \"write_query_to_file(QUERY_3, \\\"q3_95_percentile_travel_distance.sql\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_query_to_file(QUERY_3, \"q3_95_percentile_travel_distance.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614ae69",
   "metadata": {},
   "source": [
    "### Query 4\n",
    "\n",
    "The top 10 days with the highest number of hired rides for 2009, and the average distance for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "39906169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] \n",
      "WITH all_hires AS (\n",
      "    SELECT\n",
      "      DATE(pickup_datetime) AS date, \n",
      "      COUNT(taxi_id) AS trip_count,\n",
      "      AVG(distance) AS avg_distance\n",
      "    FROM taxi_trips\n",
      "    WHERE strftime('%Y',pickup_datetime) = '2009'\n",
      "\n",
      "    UNION\n",
      "\n",
      "    SELECT\n",
      "      DATE(pickup_datetime) AS date, \n",
      "      COUNT(uber_id) AS trip_count,\n",
      "      AVG(distance) AS avg_distance\n",
      "    FROM uber_trips\n",
      "    WHERE strftime('%Y',pickup_datetime) = '2009'\n",
      "    \n",
      "    GROUP BY date\n",
      "    ORDER BY trip_count DESC\n",
      ")\n",
      "SELECT date, avg_distance FROM all_hires\n",
      "LIMIT 10\n",
      "\n",
      "[sqlalchemy] [raw sql] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2009-01-30', 3.1503920333333184),\n",
       " ('2009-10-23', 2.5065120000000007),\n",
       " ('2009-08-14', 3.4534435483870976),\n",
       " ('2009-12-11', 2.89999173553719),\n",
       " ('2009-05-16', 2.855822033898306),\n",
       " ('2009-12-18', 3.130533898305084),\n",
       " ('2009-04-10', 2.8648275862068964),\n",
       " ('2009-11-06', 3.7137931034482765),\n",
       " ('2009-04-04', 2.5015391304347827),\n",
       " ('2009-05-08', 3.414600000000002)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 167;\n",
       "                var nbb_unformatted_code = \"QUERY_4 = \\\"\\\"\\\"\\nWITH all_hires AS (\\n    SELECT\\n      DATE(pickup_datetime) AS date, \\n      COUNT(taxi_id) AS trip_count,\\n      AVG(distance) AS avg_distance\\n    FROM taxi_trips\\n    WHERE strftime('%Y',pickup_datetime) = '2009'\\n\\n    UNION\\n\\n    SELECT\\n      DATE(pickup_datetime) AS date, \\n      COUNT(uber_id) AS trip_count,\\n      AVG(distance) AS avg_distance\\n    FROM uber_trips\\n    WHERE strftime('%Y',pickup_datetime) = '2009'\\n    \\n    GROUP BY date\\n    ORDER BY trip_count DESC\\n)\\nSELECT date, avg_distance FROM all_hires\\nLIMIT 10\\n\\\"\\\"\\\"\\nengine.execute(QUERY_4).fetchall()\";\n",
       "                var nbb_formatted_code = \"QUERY_4 = \\\"\\\"\\\"\\nWITH all_hires AS (\\n    SELECT\\n      DATE(pickup_datetime) AS date, \\n      COUNT(taxi_id) AS trip_count,\\n      AVG(distance) AS avg_distance\\n    FROM taxi_trips\\n    WHERE strftime('%Y',pickup_datetime) = '2009'\\n\\n    UNION\\n\\n    SELECT\\n      DATE(pickup_datetime) AS date, \\n      COUNT(uber_id) AS trip_count,\\n      AVG(distance) AS avg_distance\\n    FROM uber_trips\\n    WHERE strftime('%Y',pickup_datetime) = '2009'\\n    \\n    GROUP BY date\\n    ORDER BY trip_count DESC\\n)\\nSELECT date, avg_distance FROM all_hires\\nLIMIT 10\\n\\\"\\\"\\\"\\nengine.execute(QUERY_4).fetchall()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUERY_4 = \"\"\"\n",
    "WITH all_hires AS (\n",
    "    SELECT\n",
    "      DATE(pickup_datetime) AS date, \n",
    "      COUNT(taxi_id) AS trip_count,\n",
    "      AVG(distance) AS avg_distance\n",
    "    FROM taxi_trips\n",
    "    WHERE strftime('%Y',pickup_datetime) = '2009'\n",
    "\n",
    "    UNION\n",
    "\n",
    "    SELECT\n",
    "      DATE(pickup_datetime) AS date, \n",
    "      COUNT(uber_id) AS trip_count,\n",
    "      AVG(distance) AS avg_distance\n",
    "    FROM uber_trips\n",
    "    WHERE strftime('%Y',pickup_datetime) = '2009'\n",
    "    \n",
    "    GROUP BY date\n",
    "    ORDER BY trip_count DESC\n",
    ")\n",
    "SELECT date, avg_distance FROM all_hires\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47924ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4 = \"\"\"\n",
    "WITH all_hires AS (\n",
    "    SELECT\n",
    "      DATE(pickup_datetime) AS date, \n",
    "      COUNT(taxi_id) AS trip_count,\n",
    "      AVG(distance) AS avg_distance\n",
    "    FROM taxi_trips\n",
    "    WHERE strftime('%Y',pickup_datetime) = '2009'\n",
    "\n",
    "    UNION\n",
    "\n",
    "    SELECT\n",
    "      DATE(pickup_datetime) AS date, \n",
    "      COUNT(uber_id) AS trip_count,\n",
    "      AVG(distance) AS avg_distance\n",
    "    FROM uber_trips\n",
    "    WHERE strftime('%Y',pickup_datetime) = '2009'\n",
    "    \n",
    "    GROUP BY date\n",
    "    ORDER BY trip_count DESC\n",
    "),\n",
    "\n",
    "\n",
    "SELECT date, avg_distance FROM all_hires\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52931eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"write_query_to_file(QUERY_4, \\\"q4_top_10_days_trip_2009.sql\\\")\";\n",
       "                var nbb_formatted_code = \"write_query_to_file(QUERY_4, \\\"q4_top_10_days_trip_2009.sql\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_query_to_file(QUERY_4, \"q4_top_10_days_trip_2009.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41690b7f",
   "metadata": {},
   "source": [
    "### Query 5\n",
    "\n",
    "The top 10 windest days in 2014, and the number of hired trips for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "541c7b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] \n",
      "WITH \n",
      "    top_windest_days AS (\n",
      "        SELECT \n",
      "            DATE(DATE) AS date, \n",
      "            DailySustainedWindSpeed\n",
      "        FROM daily_weather\n",
      "        WHERE strftime('%Y',DATE) = '2014'\n",
      "        ORDER BY DailySustainedWindSpeed DESC\n",
      "        LIMIT 10\n",
      "    ),\n",
      "    daily_hired_rides AS (\n",
      "        SELECT\n",
      "          DATE(pickup_datetime) AS date, \n",
      "          COUNT(taxi_id) AS trip_count\n",
      "        FROM taxi_trips\n",
      "        WHERE strftime('%Y',pickup_datetime) = '2014'\n",
      "        GROUP BY date\n",
      "\n",
      "        UNION\n",
      "\n",
      "        SELECT\n",
      "          DATE(pickup_datetime) AS date, \n",
      "          COUNT(uber_id) AS trip_count\n",
      "        FROM uber_trips\n",
      "        WHERE strftime('%Y',pickup_datetime) = '2014'\n",
      "        GROUP BY date),\n",
      "    daily_hired_rides_combine AS (\n",
      "        SELECT date, SUM(trip_count) AS trip_count\n",
      "        FROM daily_hired_rides\n",
      "        GROUP BY date\n",
      "    )\n",
      "\n",
      "\n",
      "SELECT\n",
      "    top_windest_days.date, \n",
      "    daily_hired_rides_combine.trip_count\n",
      "FROM top_windest_days\n",
      "INNER JOIN daily_hired_rides_combine ON top_windest_days.date = daily_hired_rides_combine.date\n",
      "\n",
      "[sqlalchemy] [raw sql] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2014-02-13', 114),\n",
       " ('2014-12-07', 137),\n",
       " ('2014-01-07', 165),\n",
       " ('2014-03-13', 192),\n",
       " ('2014-03-26', 189),\n",
       " ('2014-03-29', 191),\n",
       " ('2014-01-22', 138),\n",
       " ('2014-02-14', 171),\n",
       " ('2014-11-18', 162),\n",
       " ('2014-12-09', 155)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 164;\n",
       "                var nbb_unformatted_code = \"QUERY_5 = \\\"\\\"\\\"\\nWITH \\n    top_windest_days AS (\\n        SELECT \\n            DATE(DATE) AS date, \\n            DailySustainedWindSpeed\\n        FROM daily_weather\\n        WHERE strftime('%Y',DATE) = '2014'\\n        ORDER BY DailySustainedWindSpeed DESC\\n        LIMIT 10\\n    ),\\n    daily_hired_rides AS (\\n        SELECT\\n          DATE(pickup_datetime) AS date, \\n          COUNT(taxi_id) AS trip_count\\n        FROM taxi_trips\\n        WHERE strftime('%Y',pickup_datetime) = '2014'\\n        GROUP BY date\\n\\n        UNION\\n\\n        SELECT\\n          DATE(pickup_datetime) AS date, \\n          COUNT(uber_id) AS trip_count\\n        FROM uber_trips\\n        WHERE strftime('%Y',pickup_datetime) = '2014'\\n        GROUP BY date),\\n    daily_hired_rides_combine AS (\\n        SELECT date, SUM(trip_count) AS trip_count\\n        FROM daily_hired_rides\\n        GROUP BY date\\n    )\\n\\n\\nSELECT\\n    top_windest_days.date, \\n    daily_hired_rides_combine.trip_count\\nFROM top_windest_days\\nINNER JOIN daily_hired_rides_combine ON top_windest_days.date = daily_hired_rides_combine.date\\n\\\"\\\"\\\"\\nengine.execute(QUERY_5).fetchall()\";\n",
       "                var nbb_formatted_code = \"QUERY_5 = \\\"\\\"\\\"\\nWITH \\n    top_windest_days AS (\\n        SELECT \\n            DATE(DATE) AS date, \\n            DailySustainedWindSpeed\\n        FROM daily_weather\\n        WHERE strftime('%Y',DATE) = '2014'\\n        ORDER BY DailySustainedWindSpeed DESC\\n        LIMIT 10\\n    ),\\n    daily_hired_rides AS (\\n        SELECT\\n          DATE(pickup_datetime) AS date, \\n          COUNT(taxi_id) AS trip_count\\n        FROM taxi_trips\\n        WHERE strftime('%Y',pickup_datetime) = '2014'\\n        GROUP BY date\\n\\n        UNION\\n\\n        SELECT\\n          DATE(pickup_datetime) AS date, \\n          COUNT(uber_id) AS trip_count\\n        FROM uber_trips\\n        WHERE strftime('%Y',pickup_datetime) = '2014'\\n        GROUP BY date),\\n    daily_hired_rides_combine AS (\\n        SELECT date, SUM(trip_count) AS trip_count\\n        FROM daily_hired_rides\\n        GROUP BY date\\n    )\\n\\n\\nSELECT\\n    top_windest_days.date, \\n    daily_hired_rides_combine.trip_count\\nFROM top_windest_days\\nINNER JOIN daily_hired_rides_combine ON top_windest_days.date = daily_hired_rides_combine.date\\n\\\"\\\"\\\"\\nengine.execute(QUERY_5).fetchall()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUERY_5 = \"\"\"\n",
    "WITH \n",
    "    top_windest_days AS (\n",
    "        SELECT \n",
    "            DATE(DATE) AS date, \n",
    "            DailySustainedWindSpeed\n",
    "        FROM daily_weather\n",
    "        WHERE strftime('%Y',DATE) = '2014'\n",
    "        ORDER BY DailySustainedWindSpeed DESC\n",
    "        LIMIT 10\n",
    "    ),\n",
    "    daily_hired_rides AS (\n",
    "        SELECT\n",
    "          DATE(pickup_datetime) AS date, \n",
    "          COUNT(taxi_id) AS trip_count\n",
    "        FROM taxi_trips\n",
    "        WHERE strftime('%Y',pickup_datetime) = '2014'\n",
    "        GROUP BY date\n",
    "\n",
    "        UNION\n",
    "\n",
    "        SELECT\n",
    "          DATE(pickup_datetime) AS date, \n",
    "          COUNT(uber_id) AS trip_count\n",
    "        FROM uber_trips\n",
    "        WHERE strftime('%Y',pickup_datetime) = '2014'\n",
    "        GROUP BY date),\n",
    "    daily_hired_rides_combine AS (\n",
    "        SELECT date, SUM(trip_count) AS trip_count\n",
    "        FROM daily_hired_rides\n",
    "        GROUP BY date\n",
    "    )\n",
    "\n",
    "\n",
    "SELECT\n",
    "    top_windest_days.date, \n",
    "    daily_hired_rides_combine.trip_count\n",
    "FROM top_windest_days\n",
    "INNER JOIN daily_hired_rides_combine ON top_windest_days.date = daily_hired_rides_combine.date\n",
    "\"\"\"\n",
    "engine.execute(QUERY_5).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9dc3e4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 168;\n",
       "                var nbb_unformatted_code = \"write_query_to_file(QUERY_5, \\\"q5_top_10_windest_day_trips_2014.sql\\\")\";\n",
       "                var nbb_formatted_code = \"write_query_to_file(QUERY_5, \\\"q5_top_10_windest_day_trips_2014.sql\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_query_to_file(QUERY_5, \"q5_top_10_windest_day_trips_2014.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9258a432",
   "metadata": {},
   "source": [
    "### Query 6\n",
    "Hourly trip situaiton during Hurricane Sandy in NYC (Oct 29-30, 2012), including the week leading up and the week after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "35e31198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sqlalchemy] \n",
      "\n",
      "WITH RECURSIVE dates(x) AS ( \n",
      "            SELECT '2012-10-22' \n",
      "                UNION ALL \n",
      "            SELECT DATE(x, '+1 DAYS') FROM dates WHERE x<'2012-11-06' \n",
      "        ) \n",
      "        SELECT * FROM dates\n",
      "\n",
      "[sqlalchemy] [raw sql] ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2012-10-22',),\n",
       " ('2012-10-23',),\n",
       " ('2012-10-24',),\n",
       " ('2012-10-25',),\n",
       " ('2012-10-26',),\n",
       " ('2012-10-27',),\n",
       " ('2012-10-28',),\n",
       " ('2012-10-29',),\n",
       " ('2012-10-30',),\n",
       " ('2012-10-31',),\n",
       " ('2012-11-01',),\n",
       " ('2012-11-02',),\n",
       " ('2012-11-03',),\n",
       " ('2012-11-04',),\n",
       " ('2012-11-05',),\n",
       " ('2012-11-06',)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 171;\n",
       "                var nbb_unformatted_code = \"QUERY_6_1 = \\\"\\\"\\\"\\n\\nWITH RECURSIVE dates(x) AS ( \\n            SELECT '2012-10-22' \\n                UNION ALL \\n            SELECT DATE(x, '+1 DAYS') FROM dates WHERE x<'2012-11-06' \\n        ) \\n        SELECT * FROM dates\\n\\\"\\\"\\\"\\nengine.execute(QUERY_6_1).fetchall()\";\n",
       "                var nbb_formatted_code = \"QUERY_6_1 = \\\"\\\"\\\"\\n\\nWITH RECURSIVE dates(x) AS ( \\n            SELECT '2012-10-22' \\n                UNION ALL \\n            SELECT DATE(x, '+1 DAYS') FROM dates WHERE x<'2012-11-06' \\n        ) \\n        SELECT * FROM dates\\n\\\"\\\"\\\"\\nengine.execute(QUERY_6_1).fetchall()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QUERY_6_1 = \"\"\"\n",
    "\n",
    "WITH RECURSIVE hourss(x) AS ( \n",
    "            SELECT '2012-10-22' \n",
    "                UNION ALL \n",
    "            SELECT DATE(x, '+1 DAYS') FROM dates WHERE x<'2012-11-06' \n",
    "        ) \n",
    "        SELECT * FROM dates\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "engine.execute(QUERY_6_1).fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
